{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIp0ciwkPld1oVP0f3idZE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataTak/study_deeplearning_fromscratch/blob/main/8%EC%9E%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 딥러닝"
      ],
      "metadata": {
        "id": "eV3FXu5M_nkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc9wgI1%2FbtqF7KwVGMC%2FmADkxjHzBPpSGyPh2eizyK%2Fimg.png)\n",
        "- 출처: https://huangdi.tistory.com/41"
      ],
      "metadata": {
        "id": "VB81nKTE_nbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 구현할 신경망의 특징\n",
        "    - 3*3의 작은 필터를 사용한 합성곱 계층\n",
        "    - 활성화 함수는 ReLU\n",
        "    - 완전연결 계층 뒤에 드롭아웃 계층 사용\n",
        "    - Adam을 사용해 최적화\n",
        "    - 가중치 초기값은 'He의 초기값'"
      ],
      "metadata": {
        "id": "ub0njYv3AV80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정확도를 더 높이려면"
      ],
      "metadata": {
        "id": "i2xes1vk_lS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터 확장(data augmentation)\n",
        "    - 입력 이미지(훈련 이미지)를 알고리즘을 동원해 인위적으로 확장.\n",
        "    - 데이터가 몇 개 없을 때 효과적인 수단\n",
        "    - what is the class of this image(https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html) 사이트에 논문들 정리되어 있음."
      ],
      "metadata": {
        "id": "9KWCLGO_BYUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 층을 깊게 하는 이유\n",
        "- 층을 깊게 할 수록 신경망의 매개변수 수가 줄어든다.\n",
        "- 층을 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같은 수준의 표현력을 달성할 수 있다.\n",
        "- 이유에 대하여 자세한 설명(GPT 활용)\n",
        "\n",
        "\n",
        "### 1. **깊은 신경망이 같은 수준의 표현력을 적은 매개변수로 달성할 수 있는 이유**\n",
        "- 깊은 신경망은 층이 많기 때문에 **특징(feature)**을 점진적으로 추출합니다.\n",
        "  - 초기 층에서는 **단순한 특징**(예: 이미지의 가장자리, 기본 색상 등)을 학습합니다.\n",
        "  - 중간 층에서는 이 특징들을 조합하여 **더 복잡한 패턴**(예: 눈, 코, 입 같은 구조)을 학습합니다.\n",
        "  - 마지막 층에서는 **고차원적이고 구체적인 표현**(예: 사람의 얼굴, 특정 사물)을 학습합니다.\n",
        "\n",
        "- 이 단계적 처리 방식은 **매개변수를 재사용(reuse)**할 수 있도록 해줍니다.\n",
        "  - 얕은 신경망에서는 데이터를 모든 뉴런에 직접 연결해야 해서 각 뉴런마다 새로운 가중치가 필요합니다.\n",
        "  - 깊은 신경망에서는 이전 층에서 학습된 가중치와 출력이 다음 층에서 다시 사용됩니다. 즉, **특징을 재활용**하면서도 더 높은 표현력을 얻을 수 있습니다.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **수학적 예제**\n",
        "- **얕은 신경망**:\n",
        "  - 입력 데이터가 $N$ 차원이고 출력 데이터가 $O$ 차원인 문제를 해결한다고 가정합니다.\n",
        "  - 이 경우, 한 층에서 바로 입력과 출력을 연결하면 필요한 매개변수 수는:\n",
        "    \\[\n",
        "    N \\times O\n",
        "    \\]\n",
        "\n",
        "- **깊은 신경망**:\n",
        "  - 중간에 $H$개의 은닉 뉴런을 가지는 두 개의 층으로 나눌 경우:\n",
        "    1. 첫 번째 층: $N \\times H$개의 매개변수\n",
        "    2. 두 번째 층: $H \\times O$개의 매개변수\n",
        "  - 필요한 총 매개변수 수는:\n",
        "    \\[\n",
        "    N \\times H + H \\times O\n",
        "    \\]\n",
        "  - 적절한 $H$를 선택하면 이 값이 $N \\times O$보다 작을 수 있습니다.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-gEXXbV5BtQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 활성화 함수가 신경망에 '비선형' 힘을 가하고, 비선형 함수가 겹치면서 더 복잡한 것도 표현할 수 있게 된다."
      ],
      "metadata": {
        "id": "Zu3P79p3CnKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG\n",
        "![1](https://wikidocs.net/images/page/164796/vgg_Fig_01.png)\n",
        "- 출처: https://wikidocs.net/164796"
      ],
      "metadata": {
        "id": "NIuQSjzZE4Z7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 성능명에서는 GoogLeNet에 뒤지지만 구성이 간단하여 응용하기 좋음"
      ],
      "metadata": {
        "id": "kMd5b2IsFZ1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GoogLeNet\n",
        "![1](https://wikidocs.net/images/page/164794/Inception_Fig_20.png)"
      ],
      "metadata": {
        "id": "uDkDx069FqJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GoogLeNet은 세로 방향 깊이 뿐 아니라 가로 방향도 깊다는 특징이 있음.\n",
        "- 가로 방향의 폭을 인셉션 구조라고 함. (그림)\n",
        "- 인셉션 구조는 크기가 다른 필터(와 풀링) 를 여러 개 적용하여 그 결과를 결합.\n",
        "- 인셉션 구조를 하나의 빌딩 블록으로 사용하는 것이 특징.\n",
        "- 또한 1*1 크기의 필터를 사용한 합성곱 계층을 사용: 매개변수 제거와 고속 처리에 기여"
      ],
      "metadata": {
        "id": "MkxXtdD0FyLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet"
      ],
      "metadata": {
        "id": "2Txe9-BPGQMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 층을 깊게 하는 것이 성능 향상에 중요하나, 지나치게 깊으면 학습이 잘 되지 않고 오히려 성능이 떨어지는 경우도 있음.\n",
        "- ResNet에서는 이 문제를 해결하기 위해 스킵 연결(skip connection)을 도입\n",
        "    - 스킵 연결은 입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조.\n",
        "    - ![1](https://wikidocs.net/images/page/164800/Fig_03.png)"
      ],
      "metadata": {
        "id": "vTxmrubqGU3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1](https://wikidocs.net/images/page/164800/Fig_11.png)"
      ],
      "metadata": {
        "id": "qHIVrbjEGtYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정리\n",
        "- 수많은 문제에서 신경망을 더 깊게 하여 성능을 개선할 수 있다.\n",
        "- 이미지 인식 기술 대회인 ILSVRC에서는 최근 딥러닝 기반 기법이 상위권을 독점하고 있으며, 그 깊이도 더 깊어지는 추세다.\n",
        "- 유명한 신경망으로는 VGG, GoogLeNet, ResNet이 있다.\n",
        "- GPU와 분산 학습, 비트 정밀도 감소 등으로 딥러닝을 고속화할 수 있다.\n",
        "- 딥러닝(신경망)은 사물 인식뿐 아니라 사물 검출과 분할에도 이용할 수 있다.\n",
        "- 딥러닝의 응용 분야로는 사진의 캡션 생성, 이미지 생성, 강화학습 등이 있다. 최근에는 자율 주행에도 딥러닝을 접목하고 있어 기대된다."
      ],
      "metadata": {
        "id": "WYgOKGomKTlj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-0ykcXEEbYl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}