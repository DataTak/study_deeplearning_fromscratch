{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1ITJsuHWlLKV92zPlUloc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataTak/study_deeplearning_fromscratch/blob/main/4%EC%9E%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatper4. 신경망 학습"
      ],
      "metadata": {
        "id": "7e3lc7dGUmLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 손실함수"
      ],
      "metadata": {
        "id": "9JK2w8Z-bTqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "MSE<br>\n",
        "회귀 문제에서 주로 사용되며, 예측 값과 실제 값의 차이를 제곱하여 평균을 구합니다.\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
        "$$\n"
      ],
      "metadata": {
        "id": "6838PyD7dUQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## MSE(Mean Squared Error)\n",
        "import numpy as np\n",
        "def mean_squared_error(y, t):\n",
        "    return 0.5 * np.sum((y-t)**2)"
      ],
      "metadata": {
        "id": "121IQan3VQw5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = [0.1, 0.05, 0.6, 0.0, 0.06, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
      ],
      "metadata": {
        "id": "ZzYsXIWxbjOX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(np.array(y), np.array(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zot0lcHxbwR6",
        "outputId": "25170600-0793-4ca3-8682-372ee78c405e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09805000000000003"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = [0.1, 0.05, 0.06, 0.0, 0.06, 0.6, 0.0, 0.1, 0.0, 0.0]\n",
        "mean_squared_error(np.array(y1), np.array(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM76Y4LMbz8-",
        "outputId": "afba8b8a-9c91-42f1-d3b2-3f85f1557272"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6348499999999999"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 손실함수 (MSE) 출력 값이 작으면 정답 레이블과의 오차도 작다."
      ],
      "metadata": {
        "id": "RtGi81Y_cCAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "wXd2TMgIe-Ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 교차 엔트로피 손실 (Cross-Entropy Loss)\n",
        "분류 문제에서 주로 사용되며, 예측 확률과 실제 클래스 확률의 차이를 정보 손실의 관점에서 측정합니다.\n",
        "\n",
        "$$\n",
        "\\text{Cross-Entropy} = -\\sum_{i=1}^{N} y_i \\log(\\hat{y}_i)\n",
        "$$"
      ],
      "metadata": {
        "id": "dsBLuimleBjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 요약 비교\n",
        "\n",
        "| **손실 함수**         | **사용 주제**  | **주된 목적**                  | **계산 방식**             |\n",
        "|----------------------|----------------|--------------------------------|---------------------------|\n",
        "| 평균제곱오차(MSE)     | 회귀 문제      | 예측 값과 실제 값 차이 최소화    | 예측 오차의 제곱 평균      |\n",
        "| 교차 엔트로피        | 분류 문제      | 올바른 클래스 확률 극대화       | -로그 확률 값의 합         |\n"
      ],
      "metadata": {
        "id": "Xcn09AhTeNSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CEE(Cross Entryopy Error)"
      ],
      "metadata": {
        "id": "SrojVN4kb9La"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    delta = 1e-7                         # delta를 더하는 이유는 log() 함수에 0이 입력되면 -inf 출력되어 계산 불가. 무한대 방지를 위하여 활용\n",
        "    return -np.sum(t*np.log(y+delta))"
      ],
      "metadata": {
        "id": "wpuebSpkcVDR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = [0.1, 0.05, 0.6, 0.0, 0.06, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
        "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "cross_entropy_error(np.array(y), np.array(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EWM-XIeeczs",
        "outputId": "85de3065-d26a-49e2-89dc-018b0c8b0f70"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.510825457099338"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = [0.1, 0.05, 0.06, 0.0, 0.06, 0.6, 0.0, 0.1, 0.0, 0.0]\n",
        "cross_entropy_error(np.array(y1), np.array(t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azUWcjYney9b",
        "outputId": "56a2ff71-21db-4483-84d3-7c1bf375e41f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8134090500947586"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 미니배치학습\n",
        "- 모든 데이터를 다 넣어서 손실함수를 구하는 것이 아니라 일부 데이터를 가지고 와서 학습을 수행. 이 일부를 미니배치라고 함.\n",
        "- 계산효율성, 일반화 가능성 등 다양한 장점으로 미니배치 활용"
      ],
      "metadata": {
        "id": "kBI7Ypote_bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 저자 깃 저장소 클론\n",
        "!git clone https://github.com/WegraLee/deep-learning-from-scratch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zmxqvct7e5cg",
        "outputId": "8ee56059-5e86-4a01-925e-9a6ec9187125"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-from-scratch'...\n",
            "remote: Enumerating objects: 853, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 853 (delta 9), reused 13 (delta 5), pack-reused 830 (from 1)\u001b[K\n",
            "Receiving objects: 100% (853/853), 52.33 MiB | 16.36 MiB/s, done.\n",
            "Resolving deltas: 100% (486/486), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "sys.path.append(\"/content/deep-learning-from-scratch\")  #불러온 깃 저장소를\n",
        "from dataset.mnist import load_mnist"
      ],
      "metadata": {
        "id": "Z7GZil46gjYH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"
      ],
      "metadata": {
        "id": "4etdwn93goCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5845d1-6229-445a-9a5e-5fd890747833"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(t_train.shape)\n",
        "print(x_test.shape)\n",
        "print(t_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xT7exePg0yi",
        "outputId": "0a96b053-d575-456a-ba99-4f76c9ffe360"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(60000, 10)\n",
            "(10000, 784)\n",
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]"
      ],
      "metadata": {
        "id": "MwfHeophg3QY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixCUVxkmhIZX",
        "outputId": "3d670f50-f898-454c-908b-cf239bac763b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1882, 30238, 31341, 31829, 11406, 11247, 51472, 43057, 13132,\n",
              "       35319])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#미니배치용 CEE\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(t*np.log(y))/batch_size"
      ],
      "metadata": {
        "id": "7pur1Slwjq53"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 손실함수를 설정하는 이유\n",
        "    - 신경망을 학습할 때 정확도를 지표로 삼으면 매개변수의 미분이 대부분의 장소에서 0이된다.\n",
        "        - 정확도는 매개변수의 변화에 거의 반응을 보이지 않고, 반응이 있더라도 불연속적으로 변화(계단함수 같다고 생각하면 쉬움.)\n",
        "- <GPT 활용 손실함수 사용 이유 답변>\n",
        "1. 정확도는 연속적인 피드백을 제공하지 않습니다.\n",
        "- 정확도는 예측이 정확한지 아닌지만 판단하기 때문에 모델이 어디에서 얼마나 틀렸는지를 알려주지 않습니다. - 예를 들어, 예측이 실제 값과 조금 벗어난 경우에도 정확도는 틀렸다고 표시하지만, 손실 함수는 이 차이를 구체적으로 계산해줍니다.\n",
        "- 모델이 학습하는 동안 얼마나 개선되고 있는지를 세부적으로 파악하기 위해서는 차이를 연속적인 값으로 표시하는 손실 함수가 필요합니다.\n",
        "2. 손실 함수는 미분 가능한 수치 피드백을 제공합니다.\n",
        "- 딥러닝 모델을 훈련할 때는 경사하강법을 통해 가중치를 업데이트합니다. 경사하강법은 손실 함수의 **기울기(미분)**를 사용하여 손실을 최소화하는 방향으로 가중치를 조정합니다.\n",
        "- 정확도는 불연속적인 값이므로 미분이 불가능하여, 이를 기준으로 경사하강법을 사용할 수 없습니다. 반면 손실 함수는 미분 가능하므로, 학습 과정에서 손실을 최소화하는 방향으로 모델을 최적화할 수 있습니다.\n",
        "3. 손실 함수는 세부적인 성능 차이를 학습에 반영할 수 있습니다.\n",
        "- 손실 함수는 예측값과 실제값 간의 차이를 연속적인 값으로 표현하기 때문에, 예측의 오차 크기와 방향을 모델에 피드백으로 제공할 수 있습니다.\n",
        "- 특히 회귀 문제에서 평균제곱오차(MSE)와 같은 손실 함수는 예측값이 실제값과 얼마나 가까운지를 나타내어, 모델이 세밀하게 개선될 수 있도록 돕습니다.\n",
        "- 분류 문제에서도 교차 엔트로피 손실을 통해 모델이 정확한 클래스의 확률을 더 높게 예측하도록 유도할 수 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "Yqtp6cV5lNZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 수치미분"
      ],
      "metadata": {
        "id": "t4kMMat7oBuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#수치 미분 계산 함수\n",
        "def numerical_diff(f, x):\n",
        "    h = 1e-4  #h값을 너무 작게 하면 반올림오차의 문제가 만들어진다(0으로 처리)\n",
        "    return (f(x+h) - f(x-h)) / (2*h)"
      ],
      "metadata": {
        "id": "L5xN0GKVjvau"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#기울기\n",
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4\n",
        "    grad = np.zeros_like(x)   #x와 형상이 같은 배열 생성\n",
        "\n",
        "    for idx in range(x.size):\n",
        "        tmp_val = x[idx]\n",
        "\n",
        "        x[idx] = tmp_val + h\n",
        "        fxh1 = f(x)\n",
        "\n",
        "        x[idx] = tmp_val - h\n",
        "        fxh2 = f(x)\n",
        "\n",
        "        grad[idx] = (fxh1 - fxh2)/(2*h)\n",
        "        x[idx] = tmp_val\n",
        "    return grad"
      ],
      "metadata": {
        "id": "zJ6aKPFUppoq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 경사하강법 (Gradient Descent) _ GPT활용\n",
        "\n",
        "경사하강법은 함수의 기울기를 이용하여 **최소값**을 찾아가는 최적화 알고리즘입니다. 예를 들어, 다음과 같은 함수가 있다고 가정해보겠습니다.\n",
        "\n",
        "$$\n",
        "y = x_0^2 + x_1^2\n",
        "$$\n",
        "\n",
        "이 함수의 최소값을 찾기 위해 각 변수 \\( x_0 \\)와 \\( x_1 \\)에 대한 **편미분**을 계산하여, 기울기가 가리키는 반대 방향으로 이동하며 \\( y \\) 값을 점차 줄입니다.\n",
        "\n",
        "### 1. 기울기 계산\n",
        "먼저, \\( y \\)를 \\( x_0 \\)와 \\( x_1 \\)에 대해 편미분하여 기울기를 구합니다.\n",
        "\n",
        "$$\n",
        "\\frac{\\partial y}{\\partial x_0} = 2x_0\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial y}{\\partial x_1} = 2x_1\n",
        "$$\n",
        "\n",
        "따라서, 기울기 벡터는 다음과 같이 표현됩니다.\n",
        "\n",
        "$$\n",
        "\\nabla y = \\begin{bmatrix} 2x_0 \\\\ 2x_1 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "### 2. 기울기를 이용한 변수 업데이트\n",
        "경사하강법에서는 기울기 벡터의 반대 방향으로 이동하면서 변수를 업데이트합니다. 학습률(learning rate)을 \\( \\eta \\)라고 할 때, 경사하강법에 따라 변수 \\( x_0 \\)와 \\( x_1 \\)는 다음과 같이 업데이트됩니다.\n",
        "\n",
        "$$\n",
        "x_0 = x_0 - \\eta \\cdot \\frac{\\partial y}{\\partial x_0} = x_0 - \\eta \\cdot 2x_0\n",
        "$$\n",
        "\n",
        "$$\n",
        "x_1 = x_1 - \\eta \\cdot \\frac{\\partial y}{\\partial x_1} = x_1 - \\eta \\cdot 2x_1\n",
        "$$\n",
        "\n",
        "### 3. 반복 수행\n",
        "이 과정을 반복하면 \\( x_0 \\)와 \\( x_1 \\) 값이 점차적으로 함수 \\( y \\)의 최소값을 향해 이동하게 됩니다. 학습률 \\( \\eta \\)의 값이 적절히 조절되면, 경사하강법은 수렴하여 최소값에 도달하게 됩니다.\n"
      ],
      "metadata": {
        "id": "w09sEXVcsv8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(f, init_x, lr=0.01, step_num=100):  #f: 함수 / init_x: 초깃값, lr: 학습률, step_num: 반복횟수)\n",
        "    x = init_x\n",
        "\n",
        "    for i in range(step_num):\n",
        "        grad = numerical_gradient(f, x)\n",
        "        x -= lr * grad\n",
        "    return x"
      ],
      "metadata": {
        "id": "3qsuEExLqWJI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#경사하강법으로 f(x0, x1) = x0^2 + x1^2 의 최솟값 구하기\n",
        "def function_2(x):\n",
        "    return x[0]**2 + x[1]**2"
      ],
      "metadata": {
        "id": "y7ZPNsiytNLI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_x = np.array([-3.0, 4.0])"
      ],
      "metadata": {
        "id": "aQbzmQ-3uMgA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_x = np.array([-3.0, 4.0])\n",
        "gradient_descent(function_2, init_x = init_x, lr=10.0, step_num = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfckw5Tmuiju",
        "outputId": "52273f70-7fa3-4ff9-d0ab-412d44124330"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.58983747e+13, -1.29524862e+12])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- lr의 수치에 따라서 너무 크면 발산 / 작으면 거의 갱신이 되지 않음.\n",
        "- lr과 같은 매개변수를 하이퍼파라미터(hyper parameter)라고 함.\n",
        "    - 사람이 직접 설정해야 하는 매개변수."
      ],
      "metadata": {
        "id": "VNAY_ED2vyCA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 신경망 기울기 구하기"
      ],
      "metadata": {
        "id": "Tgmv1mVh1Mxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from common.functions import softmax, cross_entropy_error\n",
        "from common.gradient import numerical_gradient"
      ],
      "metadata": {
        "id": "7LxeuFaiui1-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class simpleNet:\n",
        "    def __init__(self):\n",
        "        self.W = np.random.randn(2,3)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return np.dot(x, self.W)\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        z = self.predict(x)\n",
        "        y = softmax(z)\n",
        "        loss = cross_entropy_error(y, t)\n",
        "        return loss\n",
        ""
      ],
      "metadata": {
        "id": "FGggtMWu1cZ1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = simpleNet()\n",
        "print(net.W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ5bT_EL1vn9",
        "outputId": "1b04153c-29fa-4f09-b732-b04475e2d7ae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.68496159 -0.34648499  1.25277233]\n",
            " [ 0.99134541 -0.10017676 -2.84606048]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)"
      ],
      "metadata": {
        "id": "sMFR7gjo2_fq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUpQ6Iyn3HCI",
        "outputId": "91651550-f232-4a0d-def4-4cb596267978"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.48123392, -0.29805008, -1.80979104])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.array([0,0,1])\n",
        "net.loss(x, t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUo-akh23IOj",
        "outputId": "3ed1f24b-a4f7-479e-991a-5ab760c7f203"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.7356432549397143"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(W):\n",
        "    return net.loss(x, t)\n",
        "\n",
        "dW = numerical_gradient(f, net.W)\n",
        "dW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqcKfyzH3Qm_",
        "outputId": "4b4ad635-d653-475c-e3c7-0d2b4ffb1c41"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.38464017,  0.17644766, -0.56108783],\n",
              "       [ 0.57696026,  0.26467149, -0.84163174]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "- 신경망 학습 이루어지는 순서\n",
        " - 전제: 신경망에는 적응 가능한 가중치와 편향이 있고, 이 가중치와 편향을 훈련 데이터에 적응하도록 조정하는 과정을 '학습'이라고 한다.\n",
        " 1. 미니배치: 훈련 데이터 중 일부를 무작위로 가지고 오기. 이렇게 선별한 데이터를 미니배치라고 하며 미니 배치의 손실 함수 값을 줄이는 것이 목표\n",
        " 2. 기울기 산출: 미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게하는 방향을 제시한다.\n",
        " 3. 매개변수 갱신: 가중치 매개변수를 기울기 방향으로 아주 조금 갱신\n",
        " 4. 반복: 1~4단계 반복"
      ],
      "metadata": {
        "id": "h6ICCI0k4a_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 확률적 경사 하강법(stochastic gradient descent, SGD). 미니배치로 무작위로 데이터를 선정하기 때문에 확률적 이라고 붙여준다."
      ],
      "metadata": {
        "id": "HXBykfTR5qCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2층 신경망 클래스 구현하기"
      ],
      "metadata": {
        "id": "7TTrjcSn56ZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from common.functions import *\n",
        "from common.gradient import numerical_gradient"
      ],
      "metadata": {
        "id": "m-OivXad3s34"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TwoLayerNet:\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "        self.params['b1'] = np.zeros(hidden_size)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b2'] = np.zeros(output_size)\n",
        "\n",
        "    def predict(self, x):\n",
        "        W1, W2 = self.params['W1'], self.params['W2']\n",
        "\n",
        "        b1, b2 = self.params['b1'], self.params['b2']\n",
        "\n",
        "        a1 = np.dot(x, W1) + b1\n",
        "        z1 = sigmoid(a1)\n",
        "        a2 = np.dot(z1, W2) + b2\n",
        "        y = softmax(a2)\n",
        "\n",
        "        return y\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis = 1)\n",
        "        t = np.argmax(t, axis = 1)\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "\n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "\n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "\n",
        "        return grads"
      ],
      "metadata": {
        "id": "43G_Z25n6D43"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = TwoLayerNet(input_size=784, hidden_size=100, output_size = 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYwSISH68Poc",
        "outputId": "58d451c8-08d9-4f9e-baa6-8a81eca4d75b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(net.params['W1'].shape)\n",
        "print(net.params['b1'].shape)\n",
        "print(net.params['W2'].shape)\n",
        "print(net.params['b2'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDruNL2O8Xvx",
        "outputId": "38f120d3-5ed9-4c12-a8fb-c06cbdd18750"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(100, 10)\n",
            "(10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(100, 784)\n",
        "t = np.random.rand(100, 10)\n",
        "\n",
        "grads = net.numerical_gradient(x, t)\n"
      ],
      "metadata": {
        "id": "IdPxBrG28dJs"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위 코드로 학습하는데 3분 이상 걸림\n",
        "- 수치 미분 방식으로 계산하면 연산 속도가 느린데, 오차역전파를 이용하면 빠르게 계산 가능."
      ],
      "metadata": {
        "id": "6JZR2adH93i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(grads['W1'].shape)\n",
        "print(grads['b1'].shape)\n",
        "print(grads['W2'].shape)\n",
        "print(grads['b2'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tntSj9db8oht",
        "outputId": "4fb0db01-abfd-4208-c3e2-a3b4cffac7fa"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(784, 100)\n",
            "(100,)\n",
            "(100, 10)\n",
            "(10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 미니배치 학습 구현하기"
      ],
      "metadata": {
        "id": "I0FCZoa29eFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset.mnist import load_mnist\n",
        "from ch04.two_layer_net import TwoLayerNet"
      ],
      "metadata": {
        "id": "jb_GJbKb9CtM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label = True)\n",
        "\n",
        "train_loss_list = []\n",
        "\n",
        "#하이퍼파라미터\n",
        "iters_num = 1000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)"
      ],
      "metadata": {
        "id": "Jj9VzudP9oWQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_loss_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "c_ubNZLLALAA",
        "outputId": "51686810-95c0-4907-8e2b-ee5423a90da1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a7571f66e90>]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjsklEQVR4nO3dd3gU1foH8O+WZNNDQkiDAKGF3iGGJkggcBGFq6iIUgQrqIiK8lOxXDXYsaBcC2JDxKuCBUEITaSXIEV6IJQUWrIpJNnszu+PkMlMdrZms9lNvp/n2cfszJnZs4tkX95zzntUgiAIICIiIvJg6rruABEREZEtDFiIiIjI4zFgISIiIo/HgIWIiIg8HgMWIiIi8ngMWIiIiMjjMWAhIiIij8eAhYiIiDyetq474Aomkwnnz59HcHAwVCpVXXeHiIiI7CAIAgoKChAbGwu12noOpV4ELOfPn0dcXFxdd4OIiIiccObMGTRr1sxqm3oRsAQHBwOoeMMhISF13BsiIiKyh16vR1xcnPg9bk29CFgqh4FCQkIYsBAREXkZe6ZzcNItEREReTwGLEREROTxGLAQERGRx2PAQkRERB6PAQsRERF5PAYsRERE5PEYsBAREZHHY8BCREREHo8BCxEREXk8BixERETk8RiwEBERkcdjwEJEREQejwGLC6w9lIMV6efquhtERET1FgMWO5lMgsXj077chUeXpuNwth5l5SbZ+XKjCV9uPYWjOQUOv+bZK8WYuXQvdp++4lSfiYiI6gttXXfAG3z650m8s+YoHhnaFleKDbitdzM0CvBFeKAvisrKxXYj5v+JxPhwfDMtEXvP5GHriUvIyr+Kb3ecQbBOi6Zh/hAE4OOJvdCicSAAIDu/BGv/ycGtvZrBz0cj3mtF+jk8ujQdAHDiQhF+eXgAACAr/yre/uMoxvZoim5xjRCo4x8hERHVfypBEJRTB15Er9cjNDQU+fn5CAkJcfn9Wz79m+LxJsE6vHNbd9z12XaH7/no0LYYnNAEYz/cIh5b+chAJEQHY/XBbDz0zR5Z+4MvpuDgeT0WrD+OjUcvAAAig3X46+kb4KOxniir/CNWqVQO95OIiKi2OPL9zYDFhi3HL+LOTx0PSJzVu0UYjuUWIv+qwa72kcE6DO8UhUb+vrh3UCuE+vvIzmfnl2Dku5swqmsMXh7TpTa6TERE5BQGLC5ysbAU172ahnIL81c8TbCfFm0ig/CvzjG4d1ArfLP9NJ756YB4/t89mmJU1xj0bxMBnVbNjAsREdUpBiwucj7vKqYv2YO9mXnisfsHtYK+xICbujXF+E+2OXXfFo0DcPpSsYt66bwezRvh66mJMAoCJi/agbaRwXhlbGdobQwxERERuQIDFhcymQRcKipDicGIXacvY0z3pmJmYvFfGXjhl0OK1302qTemfrFLfJ767y6Y8+N+AMDWOTcgKXWdy/rYKTYE9/SPx+Pf73P42nv6x+O6VuG476vd4rEJic3xn5s7Q61mBoaIiGqPI9/fDv1TOjU1FX369EFwcDAiIyMxZswYHDlyxOo1n3zyCQYOHIiwsDCEhYUhOTkZO3bskLWZPHkyVCqV7DFixAhHulZr1GoVmgTrEBcegLE9msmGUSb3j5e1XXhXTwBAkE6LoR2icGPXGADA7BEJ+FeXGLFdRJAOTRv516hfh15KEX8O9tPill7NMGdke4fvs3RnJv4+my879s32TPx+IBsmk4DC0nILVxIREbmPQwHLxo0bMX36dGzbtg1r1qyBwWDA8OHDUVRUZPGaDRs2YPz48Vi/fj22bt2KuLg4DB8+HOfOyQutjRgxAllZWeLj22+/de4duZlWkoVI6RSND+7sgZWPDAQAvDymMxZP6YMHr2+NUH8fLLs/CT891A8+GjU6N5VHkjd2jcHtveOsvlb76GAAwJCEJgjwrVrOHB9RsUT6/utb487E5gj01eDXa8ugbSkuM+KD9cfNjm86egGj3t+M7i/+gYUbTyC/2L5JwERERLWhRkNCFy5cQGRkJDZu3IhBgwbZdY3RaERYWBg++OADTJw4EUBFhiUvLw/Lly93qh+1vazZmrfXHMV7accwrGMUPpnY2+7rsvNL8PaaI0iIDkFifDg6Nw3F7tOXcctHW8U2fVuG46EhrfHQN3tQXGbE4il9EBbgi1ZNAhHs54Pvd53Bsl1n8NFdvRARpANQsYS5tNwEPx8NVh3IxgNf77bUBYdNGxCPp0e2l81xKSs34XJRGaJD/Vz2OkRE1DA48v1do6pj+fkVQwnh4eF2X1NcXAyDwWB2zYYNGxAZGYmwsDDccMMNePnll9G4cWPFe5SWlqK0tFR8rtfrnei9azx8Qxv0aN4IvVuEOXRddKgfXr+1m+xYkE6+JDn1li5o3SQIP88YAJUKaN0kSHZ+XO84jKuWlVGpVGIBumC/qj/eAF8NisuMAAAfjQoGo+Nx6qebMxAZosOxnELsPHUZKZ2jsXzvOeToSzGyczQ+nNCTK4+IiKhWOL0cxGQyYebMmejfvz86d+5s93VPPfUUYmNjkZycLB4bMWIEvvzyS6SlpeG1117Dxo0bMXLkSBiNRsV7pKamIjQ0VHzExVkfSqlNPho1hiREItjPx3ZjG4L85PFjZeDRJjLILFixh/Sa1TMHYVyvZlj5yECM7hYrHj/4YgoW3NkTx18ZiadHtkeTYJ3Ve64+mIPvd5/FqUvF+O/Gk8jRVwSOvx/IxraTlx3uIxERkT2cHhJ68MEH8fvvv2Pz5s1o1qyZXdfMmzcPr7/+OjZs2ICuXbtabHfy5Em0bt0aa9euxdChQ83OK2VY4uLi6mRIyJXyiw3o9tIf4vM9zw1DeKBvje554Fw+wgN9ESuZ5Ju68h/8d9NJAMCpeaNk7TMvFWPQG+udeq23b+uGAW0isO9sPoa2j8Q320/DJACT+rV0uv9ERFR/1fqQ0IwZM/Drr79i06ZNdgcrb775JubNm4e1a9daDVYAoFWrVoiIiMDx48cVAxadTgedznomwBuFBviga7NQcdWOv2RvIWd1bhpqduyhwW1wKEuPsT2amp1rGlYV2Nx1XXNEBOkwf+0xu17rfN5VjHp/My4UlOK1W7rguRUHAQBjejQ1q8BLRETkCIcCFkEQ8PDDD+Onn37Chg0bEB8fb/siAK+//jpeeeUVrF69Gr17256YevbsWVy6dAkxMTE229Y3s4a1w+TPdwIAdNraKeAWGuCDr6YmKp7TqFXY8vQNWLk/C3cmNofRJNgdsHy6OQN511YTPfXDfvG4/qqBAQsREdWIQwHL9OnTsWTJEqxYsQLBwcHIzs4GAISGhsLfv+Jf5hMnTkTTpk2RmpoKAHjttdcwd+5cLFmyBC1bthSvCQoKQlBQEAoLC/Hiiy/illtuQXR0NE6cOIHZs2ejTZs2SElJUe5IA1FXhdtiG/lj2sBW4vPHktvBYDShZUQgCkoMuLl7U1wqLEVBaTn+/eEWtIoIhI9GjSM5BYr3e/z7fXjn9u41rj1DREQNl0NzWCytAPn8888xefJkAMDgwYPRsmVLLF68GADQsmVLnD592uya559/Hi+88AKuXr2KMWPGYO/evcjLy0NsbCyGDx+O//znP4iKirKrX3W5rNnVSgxGDH9nE9pGBuGzyX3qujs2nblcLC6p7jB3lcV2saF+2DLHfHiPiIgaLpbm93JGkwC1ynKA6KlaPv2b1fO7nk0WgxsiIqJaK81P7qFRq7wuWLFH75fXInXlP3jh54O4UFCK+WuPouXTv4l7LBEREVnCDAu5zNpDOXjomz0oM5oQGaxDszB/7JHsdC3VNjIIx3ILxed/PX0D57gQETUwHBKiOvX32Ty0aByIzccu4tnl+1FWbkJRmXIRwEq9WoThtt7NcHuf5m7qJRER1TUGLOQxBKFix+cuL/xhuzHMC9kREVH9xTks5DFUKhWCdPavnq8H8TMREdUCBixU61QqFbrHNbKrbbGNoSMiImqYGLCQW3w1tS9+eqif+PzhG9qgU6x5+u9KcZk7u0VERF6Cc1jIrfZmXoGPRi3ucfTYd+n4ae858XxKpyjMHtHeqd2piYjIu3AOC3msHs3DZBsyRgbLC8mtPpiDoW9tRLnR5O6uERGRB2PAQnVqcv+WisefXX4ABqMJufoS93aIiIg8EgMWqlMxof7Y8Yz5HkNLd57BiPmb0PfVNBw8n18HPSMiIk/CgIXqXGSwHz6Z2Nvs+IkLRQCAUe9thoFDREREDRoDFvIIyR0i8cGdPSye33z8oht7Q0REnoYBC3kElUqFG7vGQqu2vOnj9pOXkHGxCO+lHcN9X+6C0eT1C9yIiMhO9pcgJXKDQe2aYN3hXLPjUz7faXZs07ELGJIQ6Y5uERFRHWOGhTzKa7d0xYwhbRAe6GuzbamBVXGJiBoKBizkUZoE6/BESgK+vfc63Na7mdW2KpXl4SMiIqpfGLCQR0qIDsbrt3ZDNyt7EHEOCxFRw8GAhTyatWGfotJyN/aEiIjqEgMW8mhlVuqvMGAhImo4GLCQRxvYJsLiuaIyTrolImooGLCQR3tyRHuL55hhISJqOBiwkEcL0mkR7FdVLqhTbNX2499sz2TQQkTUQDBgIY8n3Ufot0cGYnK/lgCA/KsG9Ju3DsdyCgAAB87l49B5fV10kYiIahkDFvJ4ZeXyibfSLEv+VQOGvbMJV8uMuPH9zfjXe3/iYmGpu7tIRES1jAELebzq5VaaBOvM2hSUGsSfe7+8tra7REREbsaAhbxORJBCwFIin8tSbmU5NBEReR8GLOTxKoeAWjQOAKCcYdlw5ILs+eWistrvGBERuQ13ayaP99+7e+HTPzNwT/94AEBjhY0R//PrIdnz3IJSRIb4uaV/RERU+5hhIY/XLCwAL9zUCc2vZVi0GjVWzxxk9ZoLnHhLRFSvMGAhr5QQHWz1fE5+iZt6QkRE7sCAheqljItFdd0FIiJyIQYs5LV6tQizeO54bqEbe0JERLXNoYAlNTUVffr0QXBwMCIjIzFmzBgcOXLE5nXff/892rdvDz8/P3Tp0gUrV66UnRcEAXPnzkVMTAz8/f2RnJyMY8eOOfZOqMFZNLkPnvlXB9kxX23F/9L7z+VDEASly4iIyAs5FLBs3LgR06dPx7Zt27BmzRoYDAYMHz4cRUWW0+9btmzB+PHjMXXqVOzduxdjxozBmDFjcODAAbHN66+/jvfeew8LFy7E9u3bERgYiJSUFJSUcB4CWRbq74NhHaNkx4J0Wvj7aJBbUIp/sgrqqGdERORqKqEG/wy9cOECIiMjsXHjRgwapLxq4/bbb0dRURF+/fVX8dh1112H7t27Y+HChRAEAbGxsXj88cfxxBNPAADy8/MRFRWFxYsX44477rDZD71ej9DQUOTn5yMkJMRme6o/svKvIil1nfg8SKdFm8ggpJ/Jw+R+LZHUujFSOkXXYQ+JiMgSR76/azSHJT8/HwAQHh5usc3WrVuRnJwsO5aSkoKtW7cCADIyMpCdnS1rExoaisTERLFNdaWlpdDr9bIHNUy+Gvn/wm+O64oAXw0AYPGWU7j/q93ILShBXnEZDp7Pr4suEhGRCzgdsJhMJsycORP9+/dH586dLbbLzs5GVJQ8bR8VFYXs7GzxfOUxS22qS01NRWhoqPiIi4tz9m2Ql6ucswIAjyW3w4jOMWLAUiknvxSDXl+PUe9tRvqZPDf3kIiIXMHpgGX69Ok4cOAAli5d6sr+2GXOnDnIz88XH2fOnHF7H8gz6LRVwYlaVfFfPx95wHKxsBT6a3sNbToqL+FPRETewanS/DNmzMCvv/6KTZs2oVmzZlbbRkdHIycnR3YsJycH0dHR4vnKYzExMbI23bt3V7ynTqeDTme+nww1PD4alfizykLAkltQNXlbmpEhIiLv4dBvb0EQMGPGDPz0009Yt24d4uPjbV6TlJSEtLQ02bE1a9YgKSkJABAfH4/o6GhZG71ej+3bt4ttiCxRqVRmP1efRp6rryrTX33OCxEReQeHMizTp0/HkiVLsGLFCgQHB4tzTEJDQ+Hv7w8AmDhxIpo2bYrU1FQAwKOPPorrr78eb731FkaNGoWlS5di165d+PjjjwFUfMnMnDkTL7/8Mtq2bYv4+Hg899xziI2NxZgxY1z4Vqm+q4xdjCaT7Ph5SZl+H40Kd326Hc0bB+DVsV3c2T0iIqoBhwKWjz76CAAwePBg2fHPP/8ckydPBgBkZmZCra76V2y/fv2wZMkSPPvss/i///s/tG3bFsuXL5dN1J09ezaKiopw3333IS8vDwMGDMCqVavg58fddsl+KlRELMZqGZZLko0QX1t1BIWl5cBx4IXRnThERETkJRwKWOwp2bJhwwazY+PGjcO4ceMsXqNSqfDSSy/hpZdecqQ7RDKVk25NJvn/pxclAUthabn487c7MjGsYxRiG/mL16nVKhARkefhPy/J6zW9FnAM7VCxNN5YLWDZk5mneN3zPx9Ev3nrkHGxCAs3nkD3l/7AP1ms6UNE5ImcWiVE5EnWzroel4vLxMCl3ORY8eZVB7Lx2qrDAIB31hzFxxN7u7yPRERUM8ywkNfz99WIwQoAPJmSAF+NGrGh9s2Bumowij9rOCREROSRGLBQvZMQHYz9Lw7H8zd1sqt9Vt5V8ecgnRY/7jmLL7eeqqXeERGRMzgkRPWSTqsxKyBnyelLxeLPhaXlmLVsHwAguUPVhFwiIqpbzLBQveUnWbJsbaRHuoronCTbUiRZUURERHWLAQvVW/6STRCD/Xwstjt5sUj8+dyVqxbbERFR3WHAQvWWdEgo2M++0c9LRWXiz6XlJistiYjInRiwUL3lI9k3yFqGxZLScqPtRkRE5BYMWKje0knmsATp7JuAK1ViYIaFiMhTcJUQ1Vuxjfzx9Mj2CPX3wc5Tl7Hz1BWHrmeGhYjIczBgoXrtgetbAwCGdYzCpqMXcLGwDLOGtcOBc/n441CO1WuZYSEi8hwMWKhBiAjSYdezwyAIAlQqFaYv2WPzmhIDMyxERJ6Cc1ioQVGpKgqy9GvdWHZ8YNsINAuTF4ljhoWIyHMwYKEG6Y4+zfH86I7i8/F9myNIJ084vpt2FAUlBnd3jYiIFDBgoQZJo1Zhcr+W4vNgPy20Gnk53Bx9KV785ZCbe0ZEREo4h4UaLJVKheQOUThzuRh948OhUZvH738dv1gHPSMiouoYsFCD9snEXgAqghcfhQ2HBMHdPSIiIiUMWKhBq5yEC8BsSAgATIxYiIg8AuewEF2jVRgSYrhCROQZGLAQXZPSOdrsmCAA5UYTisvK66BHRERUiUNCRNfc2bc5mgTpcOBcPj5YfxwAcLGwFMPe2YT8qwZsmj3EbOkzERG5BzMsRNdo1CqM6ByN5uEBsuMZF4twuagM+8/m11HPiIiIAQtRNTof5b8Wu05dxrzfD0NfYoDAybhERG7F/DZRNTqtRvH4W2uOAgC+3ZEJH40KTwxPwB19m7uza0REDRYzLETV+FnIsFTKv2rAxcIyPP3jfjf1iIiIGLAQVePno5xhISKiusOAhagaXy3/WhAReRr+ZiaqRqMyr3hLRER1iwELUTVK8cq9A+PRKMDH7Pj1b6zHvjN5td8pIqIGjgELUTU+GvO/FjqtBr8+PMDs+OlLxXjyf/vc0S0iogaNAQtRNe2jgzG0fSTu6BMnHlOpAF+FQAbgjs5ERO7gcMCyadMmjB49GrGxsVCpVFi+fLnV9pMnT4ZKpTJ7dOrUSWzzwgsvmJ1v3769w2+GyBVUKhU+m9wH827pWnUMgNZCwKI0VERERK7lcMBSVFSEbt26YcGCBXa1f/fdd5GVlSU+zpw5g/DwcIwbN07WrlOnTrJ2mzdvdrRrRLVGpVLBR6M8GbdRgK+be0NE1PA4XOl25MiRGDlypN3tQ0NDERoaKj5fvnw5rly5gilTpsg7otUiOtp8t1wiT9A2KkhxbgsANPJnhoWIqLa5vTT/Z599huTkZLRo0UJ2/NixY4iNjYWfnx+SkpKQmpqK5s2Vy56XlpaitLRUfK7X62u1z9Rw/fBgEvZm5mFUlxiYLMxV8WHdFiKiWufW37Tnz5/H77//jmnTpsmOJyYmYvHixVi1ahU++ugjZGRkYODAgSgoKFC8T2pqqpi5CQ0NRVxcnGI7oprq1SIc0wa2gkqlgkatPCRkKDe5uVdERA2PWwOWL774Ao0aNcKYMWNkx0eOHIlx48aha9euSElJwcqVK5GXl4dly5Yp3mfOnDnIz88XH2fOnHFD74mUlZsEFJeVY+2hHPSftw5bjl+s6y4REdU7bhsSEgQBixYtwt133w1fX+uTFBs1aoR27drh+PHjiud1Oh10Ol1tdJPIYfvP5aPXf9biqsEIALjz0+04NW9UHfeKiKh+cVuGZePGjTh+/DimTp1qs21hYSFOnDiBmJgYN/SMqGaO5xaKwQoREdUOhwOWwsJCpKenIz09HQCQkZGB9PR0ZGZmAqgYrpk4caLZdZ999hkSExPRuXNns3NPPPEENm7ciFOnTmHLli0YO3YsNBoNxo8f72j3iIiIqB5yeEho165dGDJkiPh81qxZAIBJkyZh8eLFyMrKEoOXSvn5+fjhhx/w7rvvKt7z7NmzGD9+PC5duoQmTZpgwIAB2LZtG5o0aeJo94iIiKgeUgmC9xcW1+v1CA0NRX5+PkJCQuq6O1SPtXz6N/Hn9tHBOJytvJKNc1iIiGxz5PubBSSInHBrr2aYNaydxfNFpeVu7A0RUf3HgIXISdYKxuUWlFo8R0REjmPAQuQEFSzv3gwAWXlXkVtQgtSV/+D0pSL3dYyIqJ5ye2l+Im8WFuCDK8UGJHeMkh2fPSIBr686Ij6/89Pt4s9r/8lB2uOD3dVFIqJ6iQELkQPWzroeR3MKcV2rcGw4ekE8fu/AVmjdJAj3f7Xb7JoTF5hhISKqKQ4JETmgcZAOSa0bQ6VSyfYQ8tGokdIpGrf2aqZ43cVCzmkhIqoJZliInBQRbL49hJ+P8r8Ber+8Fg/f0AbpZ/IQE+qH127pCpVKeTNFIiIyx4CFyEk9m4fh2VEdEB8RKB7z02ostn9/XdXeWJP7xaNjLGsGERHZiwELUQ1MG9hK9tzf13LAIlVSzr2HiIgcwTksRC7k52NfwFIPCkwTEbkVAxYiF9JZKSYndctHW3E4W1/LvSEiqj8YsBC5kDTD8tLNnay2ffDrPbLn209ewku/HMLVMg4XERFVxzksRC6kUVet/BnY1vpu49WXOt/+8TYAQJBOg1nDE1zfOSIiL8YMC1EtiQjytXreZFKex3LyIgvNERFVx4CFyIWkc2mDdNYTmOUWAhYiIjLHgIXIhQRUBSEqlQqfT+ljsa3JwkohhjFEROYYsBC5UPUYZEhCJD64s4diW2ZYiIjsx4CFyIVSOkUDAPq0DBOPWRoaYikWIiL7cZUQkQs1CdbhwIsp8Jcsb44IMt9zyCoByC0owe/7szG2Z1OE+Pm4uJdERN6HAQuRi1XPqLSNCnLoegECJn62A4ezC7Aj4zIWTOjpyu4REXklDgkR1TKdlQ0RlQgCcDi7AACw6mB2bXSJiMjrMGAhcoP1Twx26jojJ+YSEQHgkBCRW8RHBMLfR4OrBnnZ/ez8Eny+JQMaVVWFXIORQQoRUXUMWIjcRFK1X3RdaprZsbX/5LihN0RE3oVDQkRuolIpRCxERGQXBixEbsJwhYjIeQxYiNyECRYiIucxYCFyE7XSJBYiIrILAxYiN2G4QkTkPAYsRG6i5pgQEZHTGLAQuQnjFSIi5zFgIXIbRixERM5iwELkJpxzS0TkPIcDlk2bNmH06NGIjY2FSqXC8uXLrbbfsGEDVCqV2SM7W76p24IFC9CyZUv4+fkhMTERO3bscLRrRB7N2SGh3IISHDqvd21niIi8jMMBS1FREbp164YFCxY4dN2RI0eQlZUlPiIjI8Vz3333HWbNmoXnn38ee/bsQbdu3ZCSkoLc3FxHu0fksVRODgn1fSUN/3rvT5y4UOjiHhEReQ+HA5aRI0fi5ZdfxtixYx26LjIyEtHR0eJDra566bfffhv33nsvpkyZgo4dO2LhwoUICAjAokWLHO0ekceSDgkN7xjl8PV7M/MUj5cYjHjxl4PYcuKikz0jIvJ8bpvD0r17d8TExGDYsGH466+/xONlZWXYvXs3kpOTqzqlViM5ORlbt25VvFdpaSn0er3sQeTppHsJNQnWOXy9r1b5r+tnmzPw+V+ncOcn253uGxGRp6v1gCUmJgYLFy7EDz/8gB9++AFxcXEYPHgw9uzZAwC4ePEijEYjoqLk/+KMiooym+dSKTU1FaGhoeIjLi6utt8GkUs9MrQtgv0c2yzdV6P81zXzUrErukRE5NFqPWBJSEjA/fffj169eqFfv35YtGgR+vXrh3feecfpe86ZMwf5+fni48yZMy7sMVHtaBrmL/4cFeKHfXOHO3S9Rq1CudGEN1YfxtYTl1BUWo6CEgO0GutzY1akn0O/1DTsP5vvVL+JiDyBY//Ec5G+ffti8+bNAICIiAhoNBrk5OTI2uTk5CA6Olrxep1OB53O8ZQ6UV16a1w3PLfiAO4b2AqAfG+hDjEh+CfL+tCmwWjCtzsysWD9CSxYfwIatQpGk4A7E5tbve7RpenX/rsX654YXKP3QERUV+qkDkt6ejpiYmIAAL6+vujVqxfS0tLE8yaTCWlpaUhKSqqL7hHVirjwACye0hf92kSIx55MScCITtEY2j7SypUVSsuNOJ5btVLIaBIAAPnFBrte32AyOdhjIiLP4XCGpbCwEMePHxefZ2RkID09HeHh4WjevDnmzJmDc+fO4csvvwQAzJ8/H/Hx8ejUqRNKSkrw6aefYt26dfjjjz/Ee8yaNQuTJk1C79690bdvX8yfPx9FRUWYMmWKC94ikeeaPqQNAOD9tGM225aVm1B+LUiRsjQZt6zcJDvno2adSCLyXg4HLLt27cKQIUPE57NmzQIATJo0CYsXL0ZWVhYyMzPF82VlZXj88cdx7tw5BAQEoGvXrli7dq3sHrfffjsuXLiAuXPnIjs7G927d8eqVavMJuIS1VdaCxNqpcrKTVCIVyAI5gcPndfjX+/9ifsGtRKPaVhql4i8mMMBy+DBgxV/QVZavHix7Pns2bMxe/Zsm/edMWMGZsyY4Wh3iOoFHxsTZwGgtNwEk0LEohTEvPnHEQDAx5tOisfsCYqIiDwVf4MReQB76rKUGZWHhEySf0BUBjRK/6jQMsNCRF6MAQuRBxjVJQbjejWz2qas3IQf9pw1Oy6NTcqMFRNrlXKgHBIiIm/GgIXIA2g1arwxrhsO/2cEPprQU7HNjozLiselGRYxYFGIWJhhISJvxoCFyIP4+WgwonM0nhrR3uzcaQsVbaXDRJWrjZhhIaL6hgELkYdRqVR4cHBrs+OV2ZPq1hyqKrr4yZ8Z2Hj0gvIcFjsm9hIReSoGLERe4mJhqV3tJi3aoXhcwzosROTF+BuMyEtYqSZgV1sfDgkRkRdjwEJUz4T6+0BQmMWiUauw70webnhrA9L+yVG4kojIczFgIapn8q8aYChXnsNyz+KdOHmhCFO/2FUHPSMich4DFiIP9cLojggP9MX827s7fO2OU+ZLoDVqNQpKyl3QMyIi93O4ND8Rucfk/vGY1K8lLheVueR+GhUUh4qIiLwBMyxEHkylUiEswNcl9zIKyvsOERF5AwYsRB5OXW11z4rp/Z26j8kkWN24lIjIkzFgIfIyUSF+isdtld43mjggRETeiwELkZcJ1GkUj/torP91LjcJDtVyISLyJAxYiLxMgK/yXHkfG6X3TYxWiMiLMWAh8jKWNjHU2siwGKvNuDWaBFwosK/cPxFRXWPAQuSFEqKCzY7ZqrxfPcMy58e/kZSahlUHslzZNSKiWsGAhcgL/frIALx2SxfZMbXKesRSbpQHLMt2nUW5ScADX+9xef+IiFyNAQuRF/LRqBERpJMdszRUVMnIOSxE5MUYsBB5KX9f+WohWxkWE6vGEZEXY8BC5KX8feQBCzMsRFSfMWAh8lLVlzfbmnS7NzPPoft/ve00ftl33sFeERHVDm5+SOSlqmdYbA0JOeLM5WI8u/wAAGB0t1iX3ZeIyFnMsBB5KT9f+V/f6nsOOeJ/u88iv9ggPr9SXLVDNPcfIiJPwICFyEs5OiRkzRPf78OMb6uWN0vn53KuLhF5AgYsRF6gSXDFEubGgb7iMVcPCf157KL4szSrUm4y1ei+RESuwICFyAssmZaIUV1isOTe68Rj1VcF2VolZI+k1DScuFAoy6pUL+lPRFQXGLAQeYG2UcFYMKEnEqLNS/JXcsWk26z8EsxdcQBAVZDCgIWIPAEDFqJ6wgUJFgBAYakRAjMsRORhGLAQ1RM1WSUkZSg3yYaEyhmwEJEHYMBCVE+4qg5LmdGEcmPVRFuW9CciT+BwwLJp0yaMHj0asbGxUKlUWL58udX2P/74I4YNG4YmTZogJCQESUlJWL16tazNCy+8AJVKJXu0b9/e0a4RNWiuGhIqKzfBYJKuEmLAQkR1z+GApaioCN26dcOCBQvsar9p0yYMGzYMK1euxO7duzFkyBCMHj0ae/fulbXr1KkTsrKyxMfmzZsd7RpRgybNsLRqEogXb+rk1H0MRhNOXigUn3MOCxF5AodL848cORIjR460u/38+fNlz1999VWsWLECv/zyC3r06FHVEa0W0dHRjnaHiK6RLmteMu06RIf64fmfDwIAYkL9kJVfYtd9svJL8OIvh8TnI+ZvwtAOUXhzXDeUGU24beFWJHeIxKzhCa59A0REVrh9DovJZEJBQQHCw8Nlx48dO4bY2Fi0atUKEyZMQGZmpru7RuR1FtzZU/xZmmGpXpPFV6vG//1LPsy6aHJvu16jqMyIn/edx9KdmVi6IxOHsvR4b93xGvSaiMhxbg9Y3nzzTRQWFuK2224TjyUmJmLx4sVYtWoVPvroI2RkZGDgwIEoKChQvEdpaSn0er3sQdQQjeoaI/4snXNbPWAxlJug08or4/poHPvrn6svRVGp0fFOEhG5gFt3a16yZAlefPFFrFixApGRkeJx6RBT165dkZiYiBYtWmDZsmWYOnWq2X1SU1Px4osvuqXPRN5CWjulesBSZhQQqJP/dXe0Mq7BaHLZxF4iIke5LcOydOlSTJs2DcuWLUNycrLVto0aNUK7du1w/Lhy2nnOnDnIz88XH2fOnKmNLhN5FZMkYqkeWBiMJozoHA0/n6q/8hoHl0GXGU1cMUREdcYtAcu3336LKVOm4Ntvv8WoUaNsti8sLMSJEycQExOjeF6n0yEkJET2IGropHNYVNWCEYPRhCCdFr8+PEA8ptWoMH1Ia7vvX1Zukq0YEgQBb685ioUbT5i1vVRYipHv/olFmzMceQtERBY5HLAUFhYiPT0d6enpAICMjAykp6eLk2TnzJmDiRMniu2XLFmCiRMn4q233kJiYiKys7ORnZ2N/Px8sc0TTzyBjRs34tSpU9iyZQvGjh0LjUaD8ePH1/DtETUckcE6jO4Wi1t6NkNQteEfw7VCcPKJuWo8mdIeS6Yl2nV/Q7UMy5nLV/Fe2jHM+/0wSsvlc1veSzuGf7L0eOnXQ9VvQ0TkFIcDll27dqFHjx7ikuRZs2ahR48emDt3LgAgKytLtsLn448/Rnl5OaZPn46YmBjx8eijj4ptzp49i/HjxyMhIQG33XYbGjdujG3btqFJkyY1fX9EDYYA4P3xPfDWbd3MzhmMFYGGdN5K5ZBQvzYReGiw7UyLwSjIMiwFpQbx56tl8oCloKTcob4TEdni8KTbwYMHQxAsj2MvXrxY9nzDhg0277l06VJHu0FE14zqGoPf/s7C1AHxNttaWvpcfQWRkjKjCaXlVSX7v9le9Q+T/vPWYdXMQYgLDwDA6rhE5HrcS4jIy30wvgf+fmE4OjcNtdlWukGiNGDx1dr+VVBWbkJxWVXmZIkkYCkqM+Ll36qGf8pNJhARuRIDFiIvp1KpEOLnY1dbjYUMi4/G9oqhsnKT1Tos+VerhojKjVUZlhXp5+zqGxGRNQxYiOqxr6b2RbMwf3w9tWJirXS5s1Y2JGT7V8HGoxew9p8ci+elo0DSuS6PLk23v8NERBa4tXAcEbnXwLZNsPmpG8TnNRkSssXEHZ6JqBYxw0LUgGhktVqqjtsz6daWysJ1aw7lYOPRCzW+HxGRFDMsRA2IpeJyceH+Nb63SQDmrz2K+WuP1fheRETVMcNC1ICoLfyN79UiHM/d2BEOVuuXMRhNDFaIqNYwYCFqoKrvNzR1QDyGJEQqN7ZDXrHB4rknvt/n9H2JiAAGLEQNisrCsuZK1opC2nKxsNTiuf/tPotLVs4TEdnCOSxEDUiQTotJSS1QZhQQGexndr4ma3ukVXCVlNg4T0RkDTMsRA3Mizd3Ruq/uyies5Zg+eDOHuLP82/vbrGdQuIGAFBqsFx0jojIFgYsRCSKDNZZPKeVzNgd0Tladk4apPho1Fh4V0+z64vLlAOWZ5fvx00fbDbb8ZmISIoBCxGJnhrZHkMSmuC/d/fC8I5RsnPWKuOG+FdtDeCjUaN/mwize7/5xxHF1/x6Wyb+PpuP9Yftq91SbjTh3bXHsOvUZbvaE1H9wICFiEQRQTp8PqUvUjpF44M75VmSRgFVQYlKpcKb47oBAF4Z21m2l5FWo5JlYyptOGI9ILF3w8SlO8/gnbVHcevCrXa1J6L6gZNuiUiRtFy/r0aNXi3CcGdic7RsHAAAuLVXM4zsHI1AnRbLdp1F5uViABUZFqUVSLbYu0Dp5IUih+9NRN6PAQsR2RQR5AuVSoVXx8on6wbqKn6FREnmvvioVbLhIylBEGRLq2Xn7OxLTYrbEZH34pAQEdnUxMpkXACIDq1aIq3VqGWbLEqVGeXDPtJdne2tAeNE8oaI6gEGLERkU9dmjayejwqpClh8NJYjiitFFdVwBUFAfrEBBkkAcz6vBF9vO40SK8uf08/k4WhOoZ29JqL6hENCRGTRF/f0xYq95zB7RILVdvKAxfK/g65LTcPaWddj+d5z+GD9cXw4oWpi72urDgMATl8qwjOjOppde6mwFGMW/OXoWyCieoIZFiKy6Pp2TfD27d0RLFkFpCQ8UL5KyJrPNmfgg/XHAQDfbD9tdj7tcK7idRkXzSfb5l+1vH8REdUvDFiIqMYaBfiKP1vLsACAvqQqyGgeHmh23tJUFul1lbq9+AeuFJXZ2Usi8mYMWIioxsKkAYtCDRYpo7EqIlGar3I+7yruWbwTm47K67bk6JU3T9x1+oojXSUiL8WAhYhqLExSVE6wsUC5XLIy6NB5vdn50nIT1h3OxcRFO2THc/QliveztISaiOoXBixEVGPSSreFpdb3BDp5sWqVz5GcAqttBUFAYWk5AOBioXKGxdISaiKqXxiwEFGNSYMGvY2JsI5Uqn1n7TH0eOkPbDl+EVeKle+rYSU5ogaBAQsRudSFgopMiLWdn+31XtoxGIwC7vx0u8XJtdIEiyAIeOTbvZj9v301fm0i8iwMWIjIpSqr2W54crBL73vZQsBikMyJyS0oxc/7zmPZrrPiUBIR1Q8MWIioVgT41rwuZURQVZbmfN5VxTbl1wKkcqMJG45U1XAptVIxl4i8DwMWInKJ98f3AAA8868OLruntMy/vkQ5Y2K4tkz64z9P4qkf9ovHS8pNiu2JyDuxND8RucTobrEY1LYJQgOsV8V1hD3DOpX7EX2384zs+LkrVzF3+QHc1icOKZ2iXdYnIqobzLAQkcu4MlgBgCI7ApZyU0XAYqiWUXnp14NIO5yL+7/aDUEQ7N4Nmog8EwMWInKLO/rEWTwnnasiZbIjxjCUVzQqM8oDlmOSXZ1vfH8zJn2+045eEpGnYsBCRG4x75ausjkpUiF+Wuz4v6HY/Wyy1Xs0DvQ1O2a4lmEprZZhkT4/eF6PTUcviBN0icj7OBywbNq0CaNHj0ZsbCxUKhWWL19u85oNGzagZ8+e0Ol0aNOmDRYvXmzWZsGCBWjZsiX8/PyQmJiIHTt2mN+IiLza0PZRisfLTQIiQ/zQ2EKmpVKz8ACzY5VDQQY7gpGiMq4cIvJWDgcsRUVF6NatGxYsWGBX+4yMDIwaNQpDhgxBeno6Zs6ciWnTpmH16tVim++++w6zZs3C888/jz179qBbt25ISUlBbq7yNvNE5J1S/90F0wbE47HkdrLjGjvL68eF+Zsdq9ybqMyOVUHSOTEme8abiMhjOBywjBw5Ei+//DLGjh1rV/uFCxciPj4eb731Fjp06IAZM2bg1ltvxTvvvCO2efvtt3HvvfdiypQp6NixIxYuXIiAgAAsWrTI0e4RkQcLC/TFszd2RKsmgbLjMaF+dl3fLEwhw3JtWbM98UdRaTlMJgEr0s+h8wursf6w+T+KjmQXYMrnO/DHwWy7+lSbXvj5IF757VBdd4PII9T6HJatW7ciOVk+Lp2SkoKtW7cCAMrKyrB7925ZG7VajeTkZLFNdaWlpdDr9bIHEXmeNpFBAOTl8wEgwFcje960UVXm5KMJPS3eT6ncvz1DQZWe+N/fSExNw6NL01FcZsSUxeYTcccs+Avrj1zAhxtO2H3f2pBbUILFW07hkz8zUFzGqr1EtR6wZGdnIypKPm4dFRUFvV6Pq1ev4uLFizAajYptsrOV/4WTmpqK0NBQ8REXZ3n1ARHVnU8n9saoLjH4ecYA2fHBCZEY0z1WfH7voFbizyO7xEAriXCkexs2VRgSenvNUeTqS+zqz74zeeJeR5ZcvVYhN/1Mnl33rM5VQ02VmSPAvuwRUX3nlYXj5syZg1mzZonP9Xo9gxYiD9QyIhALFDImGrUK8+/ogTfHdUP+VYPZZFtfrRrl1ybIJneIwu2943C5qAzto4MVX6fvq2mu77yCLScu4vVVR/DK2M7oFBtqdv6Br3Zj/7l8rJk1yCVbE1TiftREbghYoqOjkZOTIzuWk5ODkJAQ+Pv7Q6PRQKPRKLaJjlauTqnT6aDT1XwnWCKqW1qNWnFlkK9WjeJrAUuQTovkjhUZ2HMW9hOqKZNJwNHcArSLVA6IKt35yXYAwO3/3YZB7SIwpntTDL9WRfdCQSlWXZv3ciS7AD2ah7mufyx6R1T7Q0JJSUlIS5P/62fNmjVISkoCAPj6+qJXr16yNiaTCWlpaWIbImpYfDVVv5oCdVXzXXzsXE3kiHKjCW+vOYoR8//EvFWH7bqmsLQcK/dn476vdovHdp++XNVPje1frfoSA9YcyrFrdROHhIicyLAUFhbi+PHj4vOMjAykp6cjPDwczZs3x5w5c3Du3Dl8+eWXAIAHHngAH3zwAWbPno177rkH69atw7Jly/Dbb7+J95g1axYmTZqE3r17o2/fvpg/fz6KioowZcoUF7xFIvI2Oh9pwFL1a8re5c+O2Hc2Hx+sr/id9vGmkw5fLwgCVCoVrhQbxGP2TAS+5/Od2HX6CgDgjVu7Ylxv+bC2dCsBbitA5ETAsmvXLgwZMkR8XjmXZNKkSVi8eDGysrKQmZkpno+Pj8dvv/2Gxx57DO+++y6aNWuGTz/9FCkpKWKb22+/HRcuXMDcuXORnZ2N7t27Y9WqVWYTcYmoYZBmWIIlAYvWjsyFo275aEuNrs8rNiAs0FeWKSm3IyVSGawAwJP/+9ssYJFihoXIiYBl8ODBVqN9pSq2gwcPxt69e63ed8aMGZgxY4aj3SGieshXWzUMJM2wVC/tv+DOnpi+ZI/LXlejVsHoYHSw/1w+klo3Rml5VRVdR5ZaWyL9Ncs5LEReukqIiOo3X63tIaEp/VuicZD53kI1UT1YKTeabGZ1Ji7agYSoYIzqGiO5ruYBhjRIYcBCxICFiDyQThIkBEkzLOqq4/Z+h7doHIDYUH9sPXnJ4X6UlJsQZMcw1JGcAhxZUyA+V8rSmEwC1A7MwZHeg/EKEXdrJiIPZGnSrfQL32gSZBVyLVk763qM7dHUqX6UGJzbLPH11Ufw9bbT4vP/7T6LLi+sxuZjF+2+hzTmcXSYiqg+YsBCRB7HV5Zh0Si2MQkC4sIDsGhyb4QF+IjHWzSW7zekVatkQY8jnA1Y/snS49nlB8TnT3y/D0VlRrz060G77yFwSIhIhgELEXkcS3NYpCqTDje0j0KvFuHi8RdGd5K1U6lUsloujigx1GzyrCAIssDj3JWr+GTTSbsyJkaBQ0JEUpzDQkQeRxawWChxLw0EfLVVQ0VK2YggJzMs0pU/ztRCMZoEFJRUbVxYVGbEKyv/ke2PZIlJEisxw0LEDAsReSC15Bs92M9ShqXqS7x5eKD4s1L2wtl9faSrfcqcWKpcbhKQU2C+MeOqA8obu0rJVwlVbMbY55W1+GnvWYf7QVQfMMNCRB5HmpWwlB2RxiUzbmiDHH0JbuwaI9vluFKAr3NDQuWSNMf6w7kOX28wmpCjN98dWlo0zhJpwJL89kYxEHvsu30Y26OZw30h8nYMWIjI45yXbHJoqQ6KSRKxBOm0eOf27gCAvOIys7a2AhZfjVoxg1JWXvEagiDgga8dL1BnNAnI0ZtnWOy9VulnooaKQ0JE5HHO59veldnSvI5GAb54fFg72bEAG3NY1BZ+E1ZWrE0/k2ezP8rXC8h1MmBhjEIkx4CFiDzOhMTmAICUTpb3E7P2hX7voFa4sWsM3hrXDQDg72OeYWkcWFUlV2NhFqzBaML2k5cw9kPn9htafyRXtimiIywFZLWw/yORV+CQEBF5nEeGtkWfluHoGx9usY21lTN+Php8cGdP8bnSLs9vjOuKexbvAgCLFWgvFJRi6he77O22mdn/+xstq9WFsSRHX4Jf9p3HLT2bISzQVzbkJRUe6NrtCIi8BTMsRORxdFoNBidEWl3dU9OVvj6SuTFKAQ0A/LY/q2YvAuDUpWK72k1atAMv//YPHluWDkBeh0VKp7VvAvHWE5fw+LJ9inN6iLwRMyxE5JVqOhFVGrBoLQQsfzpQSr+mDmdX7EW04cgFHDyfjzs/2a7YzmgScOJCIVpFBEJlYShLEASM/2QbgIqaNqn/7lI7nSZyI2ZYiMgr1bSYmvSrXm1PJTc3GvXeZovnsvUlGPrWRvR+eS2KSsvNzptMgmzOzeFsfa30kcjdGLAQkVeq6SoaaYbGWsDibJXc2napqAwfrD9udvxc3lXZqiaDEwXviDwRAxYi8kqdm4bU6PpyScBiaQ4LAHSKrdnr1KZMhfkxWo38vZQrFNIj8kYMWIjIq/z+6EA8mZKAB65v7dB1q2YOxFMj2ovPpZNarQUsbSKDHO9kNW1dcA8l0j2XKlXPPJWVV2RYjCYBT//wN77bmVkrfSGqbQxYiMirdIgJwfQhbeCnUFvFmvbRIXhwcGvorn3Jd20aKp6zFrA0DfN3rqMSrZoE2m7kBF+FKsCGcvkQUOVcn9/2Z2HpzjN46of9Lu+HvsSAtH9yxOCIqDYwYCGiBmXPc8Ow45mhaBykE49ZK8bWtJH9AUtrC4FJI//aqZ3y3a4z+GH3WRzLKcC5a9sZSPc/Aip2iC4xGPHIt3vFY5cKS/HOmqM4c9m+Jde2TFu8C1O/2IX31x1zyf2IlDBgIaIGJVCnRWSwHwCg2bXsyehusRbbNwurKvx2XSvLhewAoF1UsMXXrC2Pf78PI979E/3nrcPlojJx/6NKxaXlOJ5bKDv20Dd78G7aMdzx8TYYjCZ8/lcGjuYUOPX6BqMJO05dBgD8uOecc2+CyA4MWIiowfr90YH49eEBuKF9pMU20gyLr42ibZaWWut8avdXbeWKp5nfpStmWKqvgtqeURFgnMu7isV/ncKLvxzC8Hc2OfXaqSsPiz/rFObUELkK/+8iogYr2M8HnZuGyuawtGoSKBsiahJcNXTUu0WY1ftZWmqt06qtzpNxleM5BYrLmK0tbd51+rLN++pLDLhn8U4s31uVQfnjYDYyLhZh0V8Z4jGlScBErsL/u4iowZMGEwvu7Ik+LcMVz6kAPHxDG4v3EayU01eqpuvq1UMl5SYYFJYxF5WZF5irZK1MiyAIuP+rXej6wh9YdzgXM79LBwD8dfwi7vtqN4a8uQE+kmXUOgcnQhM5ggELETV40t2afTQq5OhL7Lrufw8k4Yt7+orPLWVY/HzUsq0AKs2wEvw4o8RgVKy7or9qLWCpiliqv+8D5/RYfTBHdqx6YTrp/JySMiOe/H4ftp285GjXSaKcxf4UMWAhogZPmkXRqtV4fnQnAMCjQ9vK2qlUkO3f07tlOK5v10R8bhIEJChMvNVpNWYF3aq/risUlxlx12fmexDprxosXiMtoHfj+/ItAUrLjWbtR7+/WZYtCpRsUHkkpwDf7z6LOz7e5lC/qcpPe8+iw9xVSPsnx3bjBoYBCxE1eLKARaPCkPaR2Pf8cDw2rJ2snVajhrUQwyRAlnGppNMqZ1g0btrDKN9awCLJyFwoKJWdU8oYXS4qk31edbl1QVb+Vau1X0rLjTie69zqp7ry2Hf7YDAKmPrFrrruisdhwEJEDZ5aNiRU8Wsx1N9HPHb/9a0QHxGI8X2bQynGqMyqjO0Ri+hQP7wytrPsvJ+PBj4K2RS1kxmWsAAf240kCkosByzVd73+Ysspi+cqSbNMPtqaBV1nLhdj2c4zDu95tO9MHpJS1+H2j7dabDPxsx1IfnsTft+fVaM+kmdgwEJEDZ5aNiRk/gU8Z2QHrH9iMEL9faBSyLH88FA//PBgP4zp3hQAMCGxBZ5MSRDP67Rq+CisoNGoVIoZGVv87Zzc2rVZRTXfqwbzoZ1K1ZdB/3X8ovizpYBF+hk5WhTPYDThy62ncPJCRW2Yga+vx+wf/pYFSvZYtusMAGBvZp7FNpXLt5fs4HYE9QEDFiJq8KSre5QCCymlDEuQToteLcLkmQfZ6hk1QvzMsyIajcqsOm77aOXic1J+vrYDFl+NWgxsrAUs1YOSI9cKyBWVliMr/6riNdIAr5GD2Z7PNmdg7oqDuOGtjbLjW084NlHXkS0dlYbjyPt45r7pRERuJF2N7KO2EbDYeU+t5D46rQZhgeaZCI1KZbYfUOMg2xkLPxsF7ACgzGgS66J8vc1yhqG8WsBy+lIxyo0mTPh0u2w1kJQ0w1JicGwoZ0eGct2X6gHIG6sPY+PRC1h2fxICfM2/qiwtIVeilDUj78Owk4gaPGmFVlet3JGuCgr20yJcIROhUavMiq3FR9jeKNHfjgwLYF9mQWnYp6TcZDFYAeSTha8aLC+ZVmKpGnD1AGTB+hM4cE6PZTvPWGhv/2syw1I/8E+RiBq8yBA/PD6sHZ4d1cFmtVZ7J8pKA59Qfx/FDItapZJ9mb59Wzc0DtSZtavO3jksSrs5V1c9wwJU1HOxZvYPf4s/F5cpt60MQC4VlmL2//ZhT+aVa8dtdkmm2EJfLAU+SpSWlDujxGDEV9tO4+wV12waSY5xKmBZsGABWrZsCT8/PyQmJmLHjh0W2w4ePBgqlcrsMWrUKLHN5MmTzc6PGDHCma4RETnl4aFtMW1gK5vtrmvV2K77SZcLh/j7yOq1VKqeYQn19zHb90eJn50Bi635OIBy2f4V6eftuj8AXLUQsKT9kwsAeHb5ASzbdRb//nALAHmg8YFkd2dL4YdSITxAOfCxVHBNa2OYz17vrDmK55YfwMh3/3TJ/cgxDv8pfvfdd5g1axaef/557NmzB926dUNKSgpyc3MV2//444/IysoSHwcOHIBGo8G4ceNk7UaMGCFr9+233zr3joiIalGvFmH43wNJ2P5/Q622k2YeAn01GJwQiU8m9pa10ahVsvkVJgG4Ulxmsw/2DwnZDn5OXzLPFvzn10N23R+wnGGZ9uUuHMkuwGbJqiNAHrC8+cdRm/e3tNy5erzy6Z8n0fXFP7BPYSjLns/BHhuPXgAAFJQ4NgymxJE5OFTB4YDl7bffxr333ospU6agY8eOWLhwIQICArBo0SLF9uHh4YiOjhYfa9asQUBAgFnAotPpZO3CwqxvMkZEVFd6twxHVIif1TbFkv17KlcPDesYJWujUatkK4sEQbBvDouduz+7Y/dkayuQUuZvMvtyNzlYdb763kgmk4AD5/JhqjaU9fJv/6C4zIinf9wPQB4QuGpIyFVeX3UYia+mIbfAvi0gqIJD/zeXlZVh9+7dSE5OrrqBWo3k5GRs3Wq5eI/UZ599hjvuuAOBgfK/lBs2bEBkZCQSEhLw4IMP4tIly0vcSktLodfrZQ8iIk9SVGp9HghgXunWJAB39I0z2xKgOqU5LCM6Rcuej+oa45bJppaGhJTkXzVYmXSrfE31DMvCTSdw4/ub8aNk52ipykBGGuho1WqcuFCIJ7/fh1MXi+zur7N+3HMWb6w+bDGL8uGGE8gtKMVHG07Uel/qE4f+b7548SKMRiOiouT/SoiKikJ2drbN63fs2IEDBw5g2rRpsuMjRozAl19+ibS0NLz22mvYuHEjRo4cCaNR+S9CamoqQkNDxUdcXJwjb4OIqNYF6WwP21SfWtE9rhF0Wo3ZlgDVKe2KLN2EMLlDJN64tat7AhYbE3Slur34h1jMzV7V56W8vuqIWRtpYFBZCK9Esg+Sj0aFOz7ehu93n8U9X+wEALzw80Hc9el2i8XxlNg7ijNr2T4sWH8CO09dccn9qIJb67B89tln6NKlC/r2lVd2vOOOO8Sfu3Tpgq5du6J169bYsGEDhg41HyeeM2cOZs2aJT7X6/UMWojIo0wb1AoHz+txU/dYi20qVxLtmzsc+hIDokOtDzNVUpqTIQ2QBidEIsBXa3PFkys48oVvjaW7GCT3rz4MJLaRZFMqm0hXOqlVKnGfpJMXKjIsi69V1t164hIGtI1wstfW2TMfiezn0P/NERER0Gg0yMmR7yKZk5OD6OhoC1dVKCoqwtKlSzF16lSbr9OqVStERETg+PHjiud1Oh1CQkJkDyIiTxLi54PPJvfBzdfK9SupLPMfGuCDuPAA2bm+8eEWr1MqHBfkV/Xvz8qv7/pQf8Qg2dzQYGECzPHcQvFno0nAzlOXMeC19bJjFu/vwB5GgkP1dcnVHPq/2dfXF7169UJaWpp4zGQyIS0tDUlJSVav/f7771FaWoq77rrL5uucPXsWly5dQkxMjCPdIyLyKta+AD+c0NPiuQCFHZJl9VuujTX4ethkU1sW/5WBTzadlB0rNwkoKzchV1+COz7epnjdmA//En82mgSM/3ibbBdnpVozlaYs3mn3js6ODuF42qd/Lu+qV69Ocjj8njVrFj755BN88cUX+Oeff/Dggw+iqKgIU6ZMAQBMnDgRc+bMMbvus88+w5gxY9C4sbyGQWFhIZ588kls27YNp06dQlpaGm6++Wa0adMGKSkpTr4tIiLPJN0U0dp3R0SQ5QJySvNjIoKr2lfetsxCDRNPVGIw4oVfDuGVlf/gYmGpePxKcRn6zVuHvq+mWdzoUBqcGE2CWYBSPcNS/Uv73i93y56Xlts/L6c66bCVyo6aOkDFe/+/n/Zj3eEc242d9O2OTPSftw5zVxystdeobQ4HLLfffjvefPNNzJ07F927d0d6ejpWrVolTsTNzMxEVpZ8K+8jR45g8+bNisNBGo0Gf//9N2666Sa0a9cOU6dORa9evfDnn39Cp7Nd8ZGIyJvcKylO5+w/dgMVMiwRkj2IKu9bUGJw7gWuaRMZhO5xjWp0D3tJ9xgqlqyw2nDkgiyAscWo8KFWD2CqJ1yklWs//fMkEp5dhQ1HzGuL2fPHJR22sjfD8s32TCzZnol7Fu+y8wrHvbbqMADgq22na+01aptTk25nzJiBGTNmKJ7bsGGD2bGEhASLaSh/f3+sXr3amW4QEXkdaaE4Z+dEBCkELE0kGZnK37eFDhY4S+4QCf3Vcuw4VRE8XNcqHBluWAZcnaW5KvaonFwrZZQGEaqqlURVx6r+TF7+7R8AwBPf78OuZ4fJ2tkznCKtzKsUPCndz5GArCHz/hlZREReRLoXkd0l9jUqbJszVCwE1zHWfKGBdAipSXDFaqOiMscClgFtIrDsgSQ8mZKAjjEhmDUswWVl7R0hHeJxBWmGRaNSmQ0RKWdCnJuBIg1Y7v9qt8XtAqQC7Pz/oKFz67JmIiICnh7ZHpcKS9G6SZBd7VUqFaJD/bDv+eEwGE1mhePaRQUhLNAXH07oid2nr2Bk54pVm9e3a4KV+63XyHoyJQFvrJbXNpk+pA2mD2kDQJ4RcpdSFwcs0gBFrVKZDREpTTVROmZPPqx69iYrv8RsBVh1SpOoXc3TJgA7gwELEZGbPXB9a7va9WvdGFtOXMKdfZsDqMjIVM/K/KtLNN65vfu1n2Pwry5Vqytv7RWHsABf3PeVfFKpVMcY62Uh6qKsvSPVc+0hDVDUaiCz2v5JShtOKr5rOyIWWxN+lQTYuTdUQ8eAhYjIQ/337l7YeuISrk8w3+m5Us/mYdAp1GUBKgrTDe9kvUaWRpJBUVrVIs3mDOsYhT2nr+BSUe0WRCupwSodJUajPMNy4/ubZecVAxYbGZZtJy+hd4swaKvVuqle18XSVgQVr1HxIvUh++EOnMNCROShgv18MLxTtMWABADK7JgjcU//eADAuF7NzM5JMyhKX9LS4YxB7Zpg93PDzBspCPX3saudkimf73T6WiXV57BUp/S+lYIY6aTbOz7ehvfXmRc3La+2lPyGtzZi1ynl7Qgq72dwUbVga+xdYu3JGLAQEXmxZmHW50cAwDOjOmDlIwMxd3RHs3O2JtW2aFy1Ua21+SzBknkYHWJC8OND/Wz2y12kq4TUCu9B6V0pHaseVnyx9ZTs+eWiMtzw1gaz625daH1zYKMD1Xad5f3hCgMWIiKv9N191+HJlATc2MV2RXCNWoWOsSEI9DWfBSDLsChc27JxVUCksRKwSLcGeHVsZ7snFLuDbA6L4gRbpayL7a/4yuXlJQYjikrL8cmfJ81qvNijyME5OwfP52Pq4p04nK13/MWuydWX4KFvduOv4xedvoe7MWAhIvJCia0aY/qQNooZA0uU2tpaBSTNsFjafBAAwgOrCtclRAfb3Sd32HcmT/xZKRCx9BGcy7uKx75Lx/6z+QDMC/1VBizXpaah0/OrkefEZocfbThhtkqr0tTFO6FXKP5360dbkXY4FxM+2e7w61X6YP1xrNyfjQmfOn8Pd2PAQkTUgEmHhPoobLgoraB7Pr9E8R7Bflrc1jtOfB6gkMlxtaHtI+1uq5cU0FOqi6KcYQGe+Wk/ftp7DqM/qJikW73QX7CfFoIgIK+4Iqg4ketYkT0BVRVolaQdzsUH646jqLSq/8dyCnD12k7UNZn8XCzJ6njL/kJcJURE1IBpNSrseGYocvWlaB9tvsRZ+mVutFCB9qeH+iE+Igh5xQYktrK8y7QrfTa5D0a99ycOnndsWERpkrLiHBYVZFV+1x7KwZnLV2Vtdp66gtUHq+rcWFsR5KyPN53Ex5tO4sWbOmFSv5aYsWSvU/epHpM1l0ymztaXICbUH+VGE4oNRoT4OT9hujYxw0JE1IA8ltwOTSQbJWrVKkQG+6Fz01CL17w1rhuuaxWOKddWG1Vq0TgAKx8ZiDaRwdCoVXg0uS2ua9XYwl1cT2kljy1KRekUMyxQoZFkpdO0L5X3+Xng6z3iz7ZK8QPOZzOe/7li08JLRa4p4y8Nrs5dqQjEbnx/M7q+8Ady9cqZtLrGgIWIqAF5NLktfntkgPjcntL7t/RqhqX3JZntID28Y5TiNgHu4sxKXaV4Qek+OfoS6BwsmW/PhNuar2CWd/a3v7Pw7PL9KDeasCL9HLaeuGTXXaSB260Lt2LZzjM4nF0AAFivsPGjJ+CQEBFRAyOtRaJxopJt2uPX44+DOZjUr4Uru+WwPi3D8fe1CbE1oTTptrTcJNtB2h72ZE+klW+dSbZUD66mL6nI8Pj7aPDJnxkAgFPzRgGoWL307w+3oEfzRmb3qb5f0+wf/hZ/1tTB/lH28MxeERFRrZEuT3Zmq6DWTYLw4ODWbplca82sYe1cch+1SoXs/BKkS1YTOcPapo2VwYx0KOarbacdfg1Lf1xKwdW6w7k4lKXHN9szza4stVJNuC72j7IHAxYiogZGJfnyUnlxSbFAnRYpnaJkx4ZY2cbAEhUqliaPWfBXjfqjv2q+BLlSZWalJhNzX1t12OI+SyWGqmCp8rWk2ZyLhfK5L9aCK0eWyrsTAxYiogZGujzXQ7+b7OZTbS8fa9sYWOKqsvXS5dPVlSsEEY76aMMJFJQqv4Y0Y2ItGKlqb7kNMyxEROQRpDs+B9fhEtZmYf41voevVv415sycnHN5V203skOhhWACqApYjuYUuOS1qpNmWCoDFmtxmLWgxlpF47rESbdERA2Mn48Gv8wYAAEC/H0dz0jYa3S3WPyy7zyuaxWObSfN51gkd4hCYnw44sIDzHZQtuarqX3Fn32rZViUNjf0BJU7Rt/ykfV9hZwlLS5XkW2xHohay7D4OBH0uQMDFiKiBqhLM8t1V1zlvTu64+UxnfHxphOKAUuIvw9G2rEXElAxwXbzsYv4dHJvWWGz6kNC1YczAnw1sqqudaXcQtE9VymQBSy2X8tahsVTd3bmkBAREdUKlUqFUH8fi5VTQ/zs/zfztIHxWPZAktm9pAHL2lmDzCaM/vJwVc2Z6sNH7lDZnZrMXXFUZcBibUK1tVVC1vaMqksMWIiIqFZJN0aU6hhjveicdLjH0mRaH61K1qZ6hiVUUq3W0S/iUV1jcN+gVuLzfq0dr+KrvfYeDG4MAuyZdGutjdEk4LudmRgxf5PL5ve4AoeEiIioVoUFyAOWQe2aYHjHKPRrE2H1Ol+tGpufGgK1WmVxIqg0qNFqVGYZFukE43IHg4anUtrjxMVCfLzpJICKzQ4dpVWrUIaKOSz5VpY9u5K17AkAvL3mKC4WWt440SQIeOqH/QCAV1f+gwV39nRp/5zFgIWIiGpVo4CqLMd/xnTGHX3izOaeKDEJAiJD/Ky2kQYsGrXKLMOiq8EwkJ+PWhZs2buiKjbUT9zZujLQKjeZcO8XyvsRuVqpjVVC76Uds3r9/3afFX8uLi2HIAgwCXW/eohDQkREVKukwzK39GyqGKworUyxp8hanGTXYa1aLdsQ8d07ulsNjBbe1QvL7k+yuLxap9UgXBKwBOns+zf+oil90D2uEb6emigGUEaTgB2nHCv176zK4R5n582s/Ue+l9DFwjK0/r+V6DR3VZ3Ob2HAQkREtapZWFVQUX0ZcqVnR3UEAEzp31I8Zk9R2FZNAsWfNSqVbD+fwe0iAShnWUZ0isaIztHoGx+OtpFBivfW+agR26gqw3Oh0PZOyY0DfdE+OgTLp/fHgLYRuFJcMQw07J1Ntt+Mi7z5xxGkn8nDw9/udcn9KpdMq1TmQ27uxICFiIhqlb+vBn89fQO2PH2DOAm1uolJLbDpySGYe2NH8ZjajuW17aKCZa8jXdJbWWNm7mjzYMgevhq1rL+2sgvNwvyxdc5Qh16jNvx9Nr/G2wxUUqlUYkG8QF3t1eyxBwMWIiKqdU0b+SO2keXKtiqVCs0bB8hqgNgzydXPR4M/Zw/Bn7OHwFerlq1+qVzGfGff5tj45GA8N0oSDEm+/SzVHanMJrw/vgfaRwfj8eHtLAY97aODsWrmoDpZOu2sQe1s77u07nCuOFnY3iGx2sJJt0RE5JFC/O2b5Cqdx1JqNF+uq1Kp0KJxxdCRj0YFg1HAgDZVX9a28jiju8VidLdYAMCckR2Q3CEKvVqEof1zq8Q2YQG+LvtCj48IRMbFIpfcyxp76+As3nIKQN0HLN4TChIRUYPizDJiWzVI1j8xGO/e0R2394kTjzlS2NVXq0b/NhGy5dJAxZJqV1k763o8ltzOZfdT8vKYznZvcngku2L/oyAn/jxciQELERF5JGf+RW+rLH2zsADc3L2pbIlu9SGhZfcnYeOTgx16XXuWadtLo1bh5u6xLrtfdR1iQnDXdS2gUdvX58pJt4G+DFiIiIjMhNo5JCRVanB836DqeYa+8eHiEJI1k5JaiD+7okZJ56YhYpG2gFqc4FqZWbE3w1JUVhGwMMNCREQk8fANbdAowAdPjWjv8LVlCnNYbJEmWO6XlOK35bFhVcM2rljtu/yh/hjVtWIzyACFbIa/j2uCmMrJxPYuUS4xVHymXjmHZcGCBWjZsiX8/PyQmJiIHTt2WGy7ePFiqFQq2cPPT165UBAEzJ07FzExMfD390dycjKOHbNeiY+IiOqnx4cnYM+zw2STae1lzz461jw90v4gSboiyIk4CR/f3Uv2XLqEWik4ae7E56HE3sxKdV4XsHz33XeYNWsWnn/+eezZswfdunVDSkoKcnNzLV4TEhKCrKws8XH69GnZ+ddffx3vvfceFi5ciO3btyMwMBApKSkoKSlx/B0REZHXc7ZAmTMBi3RXY0tLnJVIi+BV1nyp7smUBIvXD+8UjeEdoxTPKQ0xlZtMWPPYILwwuqPCFfbTXHuPjlatDfS2gOXtt9/GvffeiylTpqBjx45YuHAhAgICsGjRIovXqFQqREdHi4+oqKo/IEEQMH/+fDz77LO4+eab0bVrV3z55Zc4f/48li9f7tSbIiKihunFmzoBAB4Z2tbua266NsG1RWPHMhjSjIilFU2WJs8mxocDAEZ0jrb79YwmAW2jgjGkfaQDvTRXOdfWnsq9Us6s2nIlhwKWsrIy7N69G8nJyVU3UKuRnJyMrVu3WryusLAQLVq0QFxcHG6++WYcPHhQPJeRkYHs7GzZPUNDQ5GYmGjxnqWlpdDr9bIHERFRvzYR+OelEZg1zP5lwSM7R+OHB5Pw84wBTr9uiIWNES1tRfDuHT0AVAQszcMDMK5XM5uvUbnbdE0n+FYmVs7nXXXoOq9aJXTx4kUYjUZZhgQAoqKikJ2drXhNQkICFi1ahBUrVuDrr7+GyWRCv379cPZsxW6Qldc5cs/U1FSEhoaKj7i4OMV2RETU8FganrFEpVKhV4twp1YlVQrxV/4yt7QVQWXdlgBfLTY+ORhvjOtm1mbVzIH4aEJP8XnlZoZayXLkR4a2RUsHM0OVy5Sz9VXTLnRaNbo2C7V6Xb1fJZSUlISJEyeie/fuuP766/Hjjz+iSZMm+O9//+v0PefMmYP8/HzxcebMGRf2mIiIyDFNLWw7YKmgnNZKHZhK7aNDMLJLjPi8MsMSHli1g3TmpSLxuL0q9wZ69Nqw2d3XtcCBF1PQuamNgMWbSvNHRERAo9EgJydHdjwnJwfR0faNw/n4+KBHjx44fvw4AIjX5eTkICam6g8mJycH3bt3V7yHTqeDTqdzpOtEREQu98rYztibmYcbuyrPVbE0JOTMsE5lhsVXq4ZWrUK5SUB8RBC2Z1x26D6FJRUBy+R+LdG/TQRaRQRCq1Gj3MZSp7oOWBzKsPj6+qJXr15IS0sTj5lMJqSlpSEpKcmuexiNRuzfv18MTuLj4xEdHS27p16vx/bt2+2+JxERUV2YkNgCb47rZjEAsbSEWGtnlVmgavm0NAOy/onBeHpke9wzoKUYyNir4FrAolKp0C4qWBy2Mhit36euVwk5/OqzZs3CpEmT0Lt3b/Tt2xfz589HUVERpkyZAgCYOHEimjZtitTUVADASy+9hOuuuw5t2rRBXl4e3njjDZw+fRrTpk0DUPGBzZw5Ey+//DLatm2L+Ph4PPfcc4iNjcWYMWNc906JiIjczFIg40iG5beHB+Cb7Zl4aHBr8VhceAAeuL7iuaMBi6XXtlV0r65XCTn86rfffjsuXLiAuXPnIjs7G927d8eqVavESbOZmZlQSyLHK1eu4N5770V2djbCwsLQq1cvbNmyBR07Vq0jnz17NoqKinDfffchLy8PAwYMwKpVq8wKzBEREXkTS/NTHCne1jYqGC9cW66txN45LJ9P7oNnlx/AG7d2VTxvsFHDxtHJzK6mEgTBsdDMA+n1eoSGhiI/Px8hISF13R0iIiJRy6d/Mzt2at4ol92/8/OrxYm0lnw0oadsAq+SKZ/vwPojFyyeP/LyCOi0rg1aHPn+5l5CREREbmBr2bCzyk1VmZFGARVLs0d3k08CthWsVNzHev7C0gRid6nbASkiIqIGQu1A2X9HSOIV7HwmGVp1xb59v+w7DwDo2zLcrvsobWvQJjIIx3MLATi2bUFtYIaFiIjIDWpaodaSMT0qsim9W4TBR6MWA4ufZ/THzd1j8c4d3e26j0Fh0q3Jg2aNMMNCRETkBp1jQ7D79BWX3/f50Z2QGN8YN1TbY6hrs0biFgD2UBoScnSDxNrEgIWIiKgWLbizJ3aeuoznbuyIiCAdWkYEuvT+gTotbrFjLyJblIaEjMywEBERNQyjusZgVNeKSa8PO7CLtLspZ1jqoCMWcA4LERERmc1h0ahV8KTKJwxYiIiICM/8q4PsuVatggdNYWHAQkRERMDwTtHYN3e4+NxHo/aoVUIMWIiIiAgAEHqt8BxQMSTEDAsRERF5tIohIc+JWBiwEBERkejVsV2g06rx/p09PCpg4bJmIiIiEt2Z2By39W4GrUbtUYXjmGEhIiIiGe21jQ6HdYwGALRu4tpid85ghoWIiIgUvXhzJ3SPC0VKp+i67goDFiIiIlIWpNPi7qSWdd0NABwSIiIiIi/AgIWIiIg8HgMWIiIi8ngMWIiIiMjjMWAhIiIij8eAhYiIiDweAxYiIiLyeAxYiIiIyOMxYCEiIiKPx4CFiIiIPB4DFiIiIvJ4DFiIiIjI4zFgISIiIo9XL3ZrFgQBAKDX6+u4J0RERGSvyu/tyu9xa+pFwFJQUAAAiIuLq+OeEBERkaMKCgoQGhpqtY1KsCes8XAmkwnnz59HcHAwVCqVS++t1+sRFxeHM2fOICQkxKX3pir8nN2Hn7V78HN2D37O7lFbn7MgCCgoKEBsbCzUauuzVOpFhkWtVqNZs2a1+hohISH8y+AG/Jzdh5+1e/Bzdg9+zu5RG5+zrcxKJU66JSIiIo/HgIWIiIg8HgMWG3Q6HZ5//nnodLq67kq9xs/ZffhZuwc/Z/fg5+wenvA514tJt0RERFS/McNCREREHo8BCxEREXk8BixERETk8RiwEBERkcdjwGLDggUL0LJlS/j5+SExMRE7duyo6y55jdTUVPTp0wfBwcGIjIzEmDFjcOTIEVmbkpISTJ8+HY0bN0ZQUBBuueUW5OTkyNpkZmZi1KhRCAgIQGRkJJ588kmUl5e78614lXnz5kGlUmHmzJniMX7OrnPu3DncddddaNy4Mfz9/dGlSxfs2rVLPC8IAubOnYuYmBj4+/sjOTkZx44dk93j8uXLmDBhAkJCQtCoUSNMnToVhYWF7n4rHstoNOK5555DfHw8/P390bp1a/znP/+R7TfDz9lxmzZtwujRoxEbGwuVSoXly5fLzrvqM/37778xcOBA+Pn5IS4uDq+//rpr3oBAFi1dulTw9fUVFi1aJBw8eFC49957hUaNGgk5OTl13TWvkJKSInz++efCgQMHhPT0dOFf//qX0Lx5c6GwsFBs88ADDwhxcXFCWlqasGvXLuG6664T+vXrJ54vLy8XOnfuLCQnJwt79+4VVq5cKURERAhz5sypi7fk8Xbs2CG0bNlS6Nq1q/Doo4+Kx/k5u8bly5eFFi1aCJMnTxa2b98unDx5Uli9erVw/Phxsc28efOE0NBQYfny5cK+ffuEm266SYiPjxeuXr0qthkxYoTQrVs3Ydu2bcKff/4ptGnTRhg/fnxdvCWP9MorrwiNGzcWfv31VyEjI0P4/vvvhaCgIOHdd98V2/BzdtzKlSuFZ555Rvjxxx8FAMJPP/0kO++KzzQ/P1+IiooSJkyYIBw4cED49ttvBX9/f+G///1vjfvPgMWKvn37CtOnTxefG41GITY2VkhNTa3DXnmv3NxcAYCwceNGQRAEIS8vT/Dx8RG+//57sc0///wjABC2bt0qCELFXzC1Wi1kZ2eLbT766CMhJCREKC0tde8b8HAFBQVC27ZthTVr1gjXX3+9GLDwc3adp556ShgwYIDF8yaTSYiOjhbeeOMN8VheXp6g0+mEb7/9VhAEQTh06JAAQNi5c6fY5vfffxdUKpVw7ty52uu8Fxk1apRwzz33yI79+9//FiZMmCAIAj9nV6gesLjqM/3www+FsLAw2e+Np556SkhISKhxnzkkZEFZWRl2796N5ORk8ZharUZycjK2bt1ahz3zXvn5+QCA8PBwAMDu3bthMBhkn3H79u3RvHlz8TPeunUrunTpgqioKLFNSkoK9Ho9Dh486Mbee77p06dj1KhRss8T4OfsSj///DN69+6NcePGITIyEj169MAnn3wins/IyEB2drbssw4NDUViYqLss27UqBF69+4ttklOToZarcb27dvd92Y8WL9+/ZCWloajR48CAPbt24fNmzdj5MiRAPg51wZXfaZbt27FoEGD4OvrK7ZJSUnBkSNHcOXKlRr1sV5sflgbLl68CKPRKPsFDgBRUVE4fPhwHfXKe5lMJsycORP9+/dH586dAQDZ2dnw9fVFo0aNZG2joqKQnZ0ttlH6M6g8RxWWLl2KPXv2YOfOnWbn+Dm7zsmTJ/HRRx9h1qxZ+L//+z/s3LkTjzzyCHx9fTFp0iTxs1L6LKWfdWRkpOy8VqtFeHg4P+trnn76aej1erRv3x4ajQZGoxGvvPIKJkyYAAD8nGuBqz7T7OxsxMfHm92j8lxYWJjTfWTAQm4xffp0HDhwAJs3b67rrtQ7Z86cwaOPPoo1a9bAz8+vrrtTr5lMJvTu3RuvvvoqAKBHjx44cOAAFi5ciEmTJtVx7+qPZcuW4ZtvvsGSJUvQqVMnpKenY+bMmYiNjeXn3IBxSMiCiIgIaDQas5UUOTk5iI6OrqNeeacZM2bg119/xfr169GsWTPxeHR0NMrKypCXlydrL/2Mo6OjFf8MKs9RxZBPbm4uevbsCa1WC61Wi40bN+K9996DVqtFVFQUP2cXiYmJQceOHWXHOnTogMzMTABVn5W13xvR0dHIzc2VnS8vL8fly5f5WV/z5JNP4umnn8Ydd9yBLl264O6778Zjjz2G1NRUAPyca4OrPtPa/F3CgMUCX19f9OrVC2lpaeIxk8mEtLQ0JCUl1WHPvIcgCJgxYwZ++uknrFu3zixN2KtXL/j4+Mg+4yNHjiAzM1P8jJOSkrB//37ZX5I1a9YgJCTE7IujoRo6dCj279+P9PR08dG7d29MmDBB/Jmfs2v079/fbGn+0aNH0aJFCwBAfHw8oqOjZZ+1Xq/H9u3bZZ91Xl4edu/eLbZZt24dTCYTEhMT3fAuPF9xcTHUavnXk0ajgclkAsDPuTa46jNNSkrCpk2bYDAYxDZr1qxBQkJCjYaDAHBZszVLly4VdDqdsHjxYuHQoUPCfffdJzRq1Ei2koIse/DBB4XQ0FBhw4YNQlZWlvgoLi4W2zzwwANC8+bNhXXr1gm7du0SkpKShKSkJPF85XLb4cOHC+np6cKqVauEJk2acLmtDdJVQoLAz9lVduzYIWi1WuGVV14Rjh07JnzzzTdCQECA8PXXX4tt5s2bJzRq1EhYsWKF8Pfffws333yz4tLQHj16CNu3bxc2b94stG3btkEvt61u0qRJQtOmTcVlzT/++KMQEREhzJ49W2zDz9lxBQUFwt69e4W9e/cKAIS3335b2Lt3r3D69GlBEFzzmebl5QlRUVHC3XffLRw4cEBYunSpEBAQwGXN7vD+++8LzZs3F3x9fYW+ffsK27Ztq+sueQ0Aio/PP/9cbHP16lXhoYceEsLCwoSAgABh7NixQlZWluw+p06dEkaOHCn4+/sLERERwuOPPy4YDAY3vxvvUj1g4efsOr/88ovQuXNnQafTCe3btxc+/vhj2XmTySQ899xzQlRUlKDT6YShQ4cKR44ckbW5dOmSMH78eCEoKEgICQkRpkyZIhQUFLjzbXg0vV4vPProo0Lz5s0FPz8/oVWrVsIzzzwjWyrLz9lx69evV/ydPGnSJEEQXPeZ7tu3TxgwYICg0+mEpk2bCvPmzXNJ/1WCICkdSEREROSBOIeFiIiIPB4DFiIiIvJ4DFiIiIjI4zFgISIiIo/HgIWIiIg8HgMWIiIi8ngMWIiIiMjjMWAhIiIij8eAhYiIiDweAxYiIiLyeAxYiIiIyOMxYCEiIiKP9//99/cHTjJJEAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1에폭별 훈련데이터, 시험데이터 정확도 기록하기(훈련데이터에만 적합한 오버피팅 모델이 되지 않도록 확인)\n",
        "    - 에폭(epch): 하나의 단위. 1에폭은 학습에서 훈련 데이터를 모두 소진했을 때의 횟수에 해당.\n",
        "        - 훈련데이터 10,000개를 100개의 미니배치로 학습할 경우, SGD을 100회 반복하면 훈련데이터를 소진. 100회가 1에폭!"
      ],
      "metadata": {
        "id": "mhjf0QedA3Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 위 코드에서 일부 수정\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label = True)\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "\n",
        "#하이퍼파라미터\n",
        "iters_num = 10000\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100\n",
        "learning_rate = 0.1\n",
        "\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "\n",
        "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    grad = network.gradient(x_batch, t_batch)\n",
        "\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate * grad[key]\n",
        "\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(\"train acc, test acc : \" + str(train_acc) + \", \" + str(test_acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7NyDwOuAWwo",
        "outputId": "4cb3dfee-f538-422d-84a3-cf1171ae9b4d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train acc, test acc : 0.10216666666666667, 0.101\n",
            "train acc, test acc : 0.7949833333333334, 0.8025\n",
            "train acc, test acc : 0.8771, 0.8805\n",
            "train acc, test acc : 0.89855, 0.9019\n",
            "train acc, test acc : 0.9082, 0.9106\n",
            "train acc, test acc : 0.9149333333333334, 0.9158\n",
            "train acc, test acc : 0.9197833333333333, 0.9228\n",
            "train acc, test acc : 0.9233833333333333, 0.9268\n",
            "train acc, test acc : 0.9283166666666667, 0.9299\n",
            "train acc, test acc : 0.9320166666666667, 0.934\n",
            "train acc, test acc : 0.9352, 0.9378\n",
            "train acc, test acc : 0.93825, 0.9379\n",
            "train acc, test acc : 0.9392833333333334, 0.9399\n",
            "train acc, test acc : 0.9419666666666666, 0.9426\n",
            "train acc, test acc : 0.9440333333333333, 0.9449\n",
            "train acc, test acc : 0.9460666666666666, 0.945\n",
            "train acc, test acc : 0.9480333333333333, 0.9458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정리\n",
        "- 기계학습에서 사용하는 데이터셋은 훈련 데이터와 시험 데이터로 나눠 사용\n",
        "- 훈련 데이터로 학습한 모델의 범용 능력을 시험 데이터로 평가\n",
        "- 신경망 학습은 손실함수를 지표로, 손실 함수의 값이 작아지는 방향으로 가중치 매개변수를 갱신\n",
        "- 가중치 매개변수를 갱신할 때는 가중치 매개변수의 기울기를 이용하고, 기울어진 방향으로 가중치의 값을 갱신하는 작업을 반복한다.\n",
        "- 아주 작은 값을 주엇을 때의 차분으로 미분하는 것을 수치 미분이라고 한다.\n",
        "- 수치 미분을 이용해 가중치 매개변수의 기울기를 구할 수 있다.\n",
        "- 수치 미분을 이용한 계산에는 시간이 걸리지만, 그 구현은 간단. 오차역전파를 활용하면 기울기를 고속으로 구할 수 있음."
      ],
      "metadata": {
        "id": "w7cp-4QvGvPv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "585N6CSmF3Z7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}