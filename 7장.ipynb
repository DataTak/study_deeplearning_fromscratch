{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2t/eninvSpcEM3rrARXaV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataTak/study_deeplearning_fromscratch/blob/main/7%EC%9E%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 신경망(Convolutional Neural Network)"
      ],
      "metadata": {
        "id": "F7mw2G8mKsV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 개념"
      ],
      "metadata": {
        "id": "Smw4qOzHNT7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 완전연결계층(Fully Connected)<br>\n",
        "![완전연결계층](https://cael0.github.io/assets/images/2021_08_16/7_1_1.PNG)\n",
        "- CNN 네트워크 예시<br>\n",
        "![CNN](https://cael0.github.io/assets/images/2021_08_16/7_1_2.PNG)\n",
        "-출처: https://cael0.github.io/deep%20learning/DeepLearningCh7/"
      ],
      "metadata": {
        "id": "lUBKq-1-Ln66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 합성곱계층\n",
        "- 완전연결 계층의 문제점\n",
        "    - 데이터의 형상이 무시된다.\n",
        "        - 3차원 데이터 => 1차원으로 평탄화 해서 입력\n",
        "        - 공간적 정보가 사라짐. 모든 입력 데이터를 동등한 뉴런으로 취급하여 형상에 담긴 정보를 살릴 수 없음.\n",
        "- 합성곱 계층\n",
        "    - 형상을 유지\n",
        "    - 입출력 데이터를 특징 맵(feature map) 이라고도 부름.\n"
      ],
      "metadata": {
        "id": "O-DnSGszMDI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![합성곱 연산 계산 순서](https://cael0.github.io/assets/images/2021_08_16/7_2_2_3.PNG)\n",
        "- 데이터의 형상 = (높이, 너비) = (행 개수, 열 개수)\n",
        "\n",
        "- 입력 : (4, 4) / 필터 (커널) : (3, 3) / 출력 : (2, 2)\n",
        "\n",
        "- 윈도우 (window) : 필터가 입력 데이터와 겹치는 부분\n",
        "\n",
        "- 단일 곱셈-누산 (fused multiply-add, FMA) : 대응하는 원소끼리 곱한 후 총합을 구하는 계산\n",
        "\n",
        "- 출처: 출처: https://cael0.github.io/deep%20learning/DeepLearningCh7/"
      ],
      "metadata": {
        "id": "gJoDo-m-M2f2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 패딩"
      ],
      "metadata": {
        "id": "rJ4qvpm_NSWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Padding(패딩)\n",
        "    - 합성곱 연산 수행 전 입력 데이터 주변을 특정 값으로 채우는 것.\n",
        "    - 패딩은 출력 크기를 조절할 목적으로 사용\n",
        "        - (4,4) 입력 데이터에 (3,3) 필터를 적용하면 출력은 (2,2)\n",
        "        - 합성곱 연산을 거칠 때 마다 크기가 작아지면 어느순간 출력 크기가 1."
      ],
      "metadata": {
        "id": "EdeW5DpcNV_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 스트라이드"
      ],
      "metadata": {
        "id": "7H9gRu3TNwBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Stride(스트라이드):  필터를 적용하는 위치의 간격<br>\n",
        "![스트라이드](https://cael0.github.io/assets/images/2021_08_16/7_2_4.PNG)\n"
      ],
      "metadata": {
        "id": "U6znomN6N55l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 스트라이드를 크게 하면 => 출력의 크기는 작아진다.\n",
        "- 패딩을 크게 하면 => 출력의 크기가 커진다.<br>\n",
        "- 입력 크기(H,W), 필터 크기(FH, FW), 출력 크기(OH, OW), 패딩 P, 스트라이드 S 일 때 출력의 크기\n",
        "- $\n",
        "O_H = \\frac{H + 2P - F_H}{S} + 1\n",
        "$\n",
        "\n",
        "- $\n",
        "O_W = \\frac{W + 2P - F_W}{S} + 1\n",
        "$\n"
      ],
      "metadata": {
        "id": "0JJ6fLu5OLao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3차원 합성곱 신경망\n",
        "![3차원합성곱](https://cael0.github.io/assets/images/2021_08_16/7_2_5_2.PNG)\n",
        "- 출처는 기존과 동일\n",
        "- 연산시 주의점\n",
        "    - 입력 데이터의 채널 수와 필터의 채널수가 같아야 함.\n",
        "    - 모든 채널의 필터 크기는 같아야 함.<br>\n",
        "![여러 필터를 사용한 합성곱연산](https://cael0.github.io/assets/images/2021_08_16/7_2_6_2.PNG)"
      ],
      "metadata": {
        "id": "TPrWzCwIPWpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 배치처리\n",
        "![배치처리](https://cael0.github.io/assets/images/2021_08_16/7_2_7.PNG)\n",
        "- 4차원으로 저장(데이터의 수, 채널 수, 높이, 너비)\n",
        "- 신경망에 4차원 데이터가 하나 흐를 때마다 데이터 N개에 대한 합성곱 연산이 이뤄진다.(N회 분의 처리를 한 번에 수행)"
      ],
      "metadata": {
        "id": "h1Ranvrvlggu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 풀링계층"
      ],
      "metadata": {
        "id": "sPysFGowl2dB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![풀링](https://cael0.github.io/assets/images/2021_08_16/7_3.PNG)\n",
        "- 2*2 최대풀링(max pooling)을 스트라이드 2로 처리하는 순서\n",
        "- 평균 풀링도 있는데 이미지 인식에서는 주로 맥스풀링 사용"
      ],
      "metadata": {
        "id": "3FqFNzSvmojS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 풀링 계층의 특징\n",
        "    - 학습해야 할 매개변수가 없다.\n",
        "    - 채널 수가 변하지 않는다.\n",
        "    - 입력의 변화에 영향을 적게 받는다(강건하다)."
      ],
      "metadata": {
        "id": "pGCAbZTnm8W1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 합성곱/풀링 계층 구현"
      ],
      "metadata": {
        "id": "aGYl4sTwnMgI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3O0Uzf4KqO-",
        "outputId": "1d6f3aef-4778-4fd5-acf9-48ec62587b54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# 4차원 배열\n",
        "import numpy as np\n",
        "x = np.random.rand(10, 1, 28, 28)  #(데이터수,  채널, 높이, 너비)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCOftNW9nkD4",
        "outputId": "2842c947-85d5-4688-f13c-4c8d5465014e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0, 0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzBAeDNsnpTX",
        "outputId": "6b378137-51bd-4fa4-9d27-eeb6c694d933"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## im2col\n",
        "- image to column의 약자. (이미지에서 행렬로!)<br>\n",
        "![im2col](https://cael0.github.io/assets/images/2021_08_16/7_4_2_3.PNG)"
      ],
      "metadata": {
        "id": "ok8vjwFboP8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 저자 깃 저장소 클론\n",
        "!git clone https://github.com/WegraLee/deep-learning-from-scratch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoFcLe7_nzbW",
        "outputId": "518e0897-fcbd-48ef-c3d6-3329582938d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-from-scratch'...\n",
            "remote: Enumerating objects: 853, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 853 (delta 9), reused 13 (delta 5), pack-reused 830 (from 1)\u001b[K\n",
            "Receiving objects: 100% (853/853), 52.33 MiB | 34.44 MiB/s, done.\n",
            "Resolving deltas: 100% (486/486), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "sys.path.append(\"/content/deep-learning-from-scratch\")  #불러온 깃 저장소를\n",
        "from dataset.mnist import load_mnist"
      ],
      "metadata": {
        "id": "F188h0e8oopX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
        "    \"\"\"\n",
        "    다수의 이미지를 입력받아 2차원 배열로 변환 (평탄화)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
        "    filter_h : 필터의 높이\n",
        "    filter_w : 필터의 너비\n",
        "    stride : 스트라이드\n",
        "    pad : 패딩\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    col : 2차원 배열\n",
        "    \"\"\"\n",
        "\n",
        "    N, C, H, W = input_data.shape\n",
        "    out_h = (H + 2 * pad - filter_h) // stride + 1\n",
        "    out_w = (W + 2 * pad - filter_w) // stride + 1\n",
        "\n",
        "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
        "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
        "\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride * out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride * out_w\n",
        "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
        "\n",
        "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)\n",
        "    return col"
      ],
      "metadata": {
        "id": "nbwhu22BoqI-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = np.random.rand(1, 3, 7, 7)  # (데이터 수, 채널 수, 높이, 너비)\n",
        "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
        "print(col1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4hCF22oo5Me",
        "outputId": "383261a2-8b43-4646-d1ce-3f7c8fd09288"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9, 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 출력결과 이해\n",
        "\n",
        "## 이미지와 필터 정보\n",
        "1. **입력 이미지 크기**: $3 \\times 7 \\times 7$\n",
        "   - $3$: 채널 수 (예: RGB)\n",
        "   - $7 \\times 7$: 각 채널의 높이와 너비\n",
        "2. **필터 크기**: $5 \\times 5$\n",
        "   - 각 채널에서 $5 \\times 5 = 25$개의 픽셀을 커버합니다.\n",
        "3. **스트라이드**: $1$\n",
        "   - 필터가 한 픽셀씩 움직이며 $3 \\times 3 = 9$개의 윈도우를 생성합니다.\n",
        "\n",
        "---\n",
        "\n",
        "## `im2col`의 동작\n",
        "1. **윈도우 개수**:\n",
        "   - $3 \\times 3 = 9$: 출력 특징 맵의 크기 (윈도우의 개수).\n",
        "2. **각 윈도우의 데이터**:\n",
        "   - 필터는 각 채널에서 $5 \\times 5 = 25$개의 픽셀을 가져옵니다.\n",
        "   - $3$개의 채널 데이터를 결합하므로, $25 \\times 3 = 75$개의 데이터를 하나의 윈도우에 포함합니다.\n",
        "3. **최종 결과**:\n",
        "   - $9$개의 윈도우 각각에서 $75$개의 데이터를 가지므로, `im2col`의 결과는 $(9, 75)$ 크기를 가집니다.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "HRU74uYwvabk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = np.random.rand(10, 3, 7, 7)  # (데이터 수, 채널 수, 높이, 너비)\n",
        "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
        "print(col2.shape)  # (90, 75)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gCuL46QpM6k",
        "outputId": "2090eea8-522a-46f8-84d2-bbf76849d9a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90, 75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 합성곱층 구현"
      ],
      "metadata": {
        "id": "20y42wfQ4Akr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolution:\n",
        "    def __init__(self, W, b, stride=1, pad=0):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "    def forward(self, x):\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
        "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
        "\n",
        "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
        "        col_w = self.W.reshape(FN, -1).T\n",
        "        out = np.dot(col, col_w) + self.b\n",
        "\n",
        "        out = out.reshpae(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "zfJ8tNlC0XXz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 4차원 입력 데이터 x를 im2col 함수를 통해 2차원으로 만들어주고, 이 행렬과 곱할 수 있도록 필터 W의 형상을 바꿔줌\n",
        "- 행렬 곱 후 편향을 더한 결과를 다시 4차원으로 만들어주고, 축의 순서를 원래대로 변경함"
      ],
      "metadata": {
        "id": "IY-RIMC137UO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 풀링층 구현"
      ],
      "metadata": {
        "id": "4zhdba9D4FFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1](https://cael0.github.io/assets/images/2021_08_16/7_4_4_1.PNG)<br>\n",
        "![2](https://cael0.github.io/assets/images/2021_08_16/7_4_4_2.PNG)"
      ],
      "metadata": {
        "id": "q9vh3fKY4Lmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Pooling:\n",
        "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
        "        self.pool_h = pool_h\n",
        "        self.pool_w = pool_w\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
        "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
        "\n",
        "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
        "        col = col.reshpae(-1, self.pool_h * self.pool_w)\n",
        "\n",
        "        out = np.max(col, axis = 1)\n",
        "\n",
        "        out = out.reshpae(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "G4GgESm52xHz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 입력 데이터 전개\n",
        "2. 행별 최댓값 구하기\n",
        "3. 적절한 모양 성형"
      ],
      "metadata": {
        "id": "mS59xq7W7BRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN 구현"
      ],
      "metadata": {
        "id": "4XUP-n3a7cbH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1](https://cael0.github.io/assets/images/2021_08_16/7_5.PNG)"
      ],
      "metadata": {
        "id": "25bxnkvs7Hnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleConvNet:\n",
        "    def __init__(self, input_dim=(1, 28, 28),\n",
        "                conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
        "                hidden_size=100, output_size=10, weight_init_std=0.01):\n",
        "        filter_num = conv_param['filter_num']\n",
        "        filter_size = conv_param['filter_size']\n",
        "        filter_pad = conv_param['pad']\n",
        "        filter_stride = conv_param['strid']\n",
        "        input_size = input_dim[1]\n",
        "        conv_output_size = (input_size - filter_size + 2 * filter_pad) / filter_stride + 1\n",
        "        pool_output_size = int(filter_num * (conv_output_size / 2) ** 2)\n",
        "\n",
        "        # 가중치 매개변수 초기화\n",
        "        self.params = {}\n",
        "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0],\n",
        "                                                             filter_size, filter_size)\n",
        "        self.params['b1'] = np.zeros(filter_num)\n",
        "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
        "        self.params['b2'] = np.zeros(hidden_size)\n",
        "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "        self.params['b3'] = np.zeros(output_size)\n",
        "\n",
        "        # 계층 생성\n",
        "        self.layers = OrderedDict()\n",
        "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
        "                                            conv_param['stride'], conv_param['pad'])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
        "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
        "        self.layers['Relu2'] = Relu()\n",
        "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
        "        self.last_layer = SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer.forward(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return self.last_layer.forward(y, t)\n",
        "\n",
        "    def gradient(self, x, t):\n",
        "        # 순전파\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # 역전파\n",
        "        dout = 1\n",
        "        dout = self.last_layer.backward(dout)\n",
        "\n",
        "        layes = reversed(self.layers.values())\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        # 기울기 저장\n",
        "        grads = {}\n",
        "        grads['W1'] = self.layers['Conv1'].dW\n",
        "        grads['b1'] = self.layers['Conv1'].db\n",
        "        grads['W2'] = self.layers['Affine1'].dW\n",
        "        grads['b2'] = self.layers['Affine1'].db\n",
        "        grads['W3'] = self.layers['Affine2'].dW\n",
        "        grads['b3'] = self.layers['Affine2'].db\n",
        "\n",
        "        return grads"
      ],
      "metadata": {
        "id": "FQKWDK9-7eyl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN 시각화하기"
      ],
      "metadata": {
        "id": "QvAc_Ye78yUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![1](https://cael0.github.io/assets/images/2021_08_16/7_6_1_1.PNG)"
      ],
      "metadata": {
        "id": "0FGzDTW-9Kfi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습 전 필터는 무작위로 초기화 되어 있어 흑백의 정도에 규칙성이 없음\n",
        "- 학습을 마친 필터는 규칙성 있는 이미지가 되었음.\n",
        "- ![2](https://cael0.github.io/assets/images/2021_08_16/7_6_1_2.PNG)"
      ],
      "metadata": {
        "id": "pEZCwZ2V9PWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 층 깊이에 따른 추출 정보 변화\n",
        "![1](https://cael0.github.io/assets/images/2021_08_16/7_6_2.PNG)"
      ],
      "metadata": {
        "id": "zLbHRjvD9_g2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 합성곱 계층을 여러 겹 쌓으면 층이 깊어지면서 더 복잡하고 추상회된 정보가 추출됨.\n",
        "- 처음 층은 단순한 에지에 반응, 텍스처 반응, 복잡한 사물의 일부에 반응..\n",
        "- 층이 깊어지면서 뉴런이 반응하는 대상이 단순한 모양에서 고급 정보로 변화해 감.(사물의 의미 이해)"
      ],
      "metadata": {
        "id": "ht1md4hB-El7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 대표적인 CNN\n",
        "- LeNet\n",
        "    - 손글씨 숫자 인식 네트워크(1988년 제안)\n",
        "    - 활성화 함수로 시그모이드 사용\n",
        "    - 서브샘플링을 하여 중간 데이터의 크기가 작아짐\n",
        "- AlexNet\n",
        "    - 2012년 발표\n",
        "    - 합성곱 계층과 풀링 계층을 거듭하며 마지막으로 완전연결계층을 거쳐 결과 출력\n",
        "    - 활성화 함수로 ReLU 사용\n",
        "    - LRN(Local Response Normalization)이라는 국소적 정규화를 실시하는 계층 이용\n",
        "    - 드롭아웃 사용"
      ],
      "metadata": {
        "id": "AKQptSkV-hGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정리\n",
        "- CNN은 지금까지 완전연결 계층 네트워크에 합성곱 계층과 풀링 계층을 새로 추가한다.\n",
        "- 합성곱 계층과 풀링 계층은 im2col(이미지를 행렬로 전개하는 함수)를 이용하면 간단하고 효율적으로 구현할 수 있다.\n",
        "- CNN을 시각화해보면 계층이 깊어질수록 고급 정보가 추출되는 모습을 확인할 수 있다.\n",
        "- 대표적인 CNN에는 LeNet과 AlexNet이 있다.\n",
        "- 딥러닝의 발전에는 빅 데이터와 GPU가 크게 기여했다."
      ],
      "metadata": {
        "id": "bmhVpAU1_CZh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ZZFawer762l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}